\documentclass[
book,
%a4paper,					% alle weiteren Papierformat einstellbar
%landscape,					% Querformat
11pt,						% SchriftgrößŸe (12pt, 11pt (Standard))
BCOR0.8cm,					% Bindekorrektur, bspw. 1 cm
%DIVcalc,					% führt die Satzspiegelberechnung neu aus
twoside,					% einseitiges Layout
%twocolumn,					% zweispaltiger Satz
%openany,					% Kapitel können auch auf linken Seiten beginnen
%halfparskip*,				% Absatzformatierung s. scrguide 3.1
%notitlepage,				% in-page-Titel, keine eigene Titelseite
%chapterprefix,				% vor Kapitelüberschrift wird "Kapitel Nummer" gesetzt
%appendixprefix,			% Anhang wird "Anhang" vor die Üœberschrift gesetzt 
%normalheadings,			% Üœberschriften etwas kleiner (smallheadings)
%idxtotoc,					% Index im Inhaltsverzeichnis
%liststotoc,				% Abb.- und Tab.verzeichnis im Inhalt
%bibtotoc,					% Literaturverzeichnis im Inhalt
bibliography=totoc,
%leqno,						% Nummerierung von Gleichungen links
%fleqn,						% Ausgabe von Gleichungen linksbündig
%draft						% Überlangen Zeilen in Ausgabe gekennzeichnet
]{scrreprt}

% ============================ Packages ============================ 

%\usepackage[inner=3.0cm,outer=2.5cm,top=1.5cm,bottom=1.5cm,includeheadfoot]{geometry}
									% Einstellungen der Seitenränder
\usepackage[includeheadfoot]{geometry}
\usepackage[T1]{fontenc}				% neue Rechtschreibung
\usepackage[latin1]{inputenc}		         % Umlaute ermöglichen
\usepackage[german, english]{babel}
\usepackage{fancyhdr}				% für Kopf- und FußŸzeile
\usepackage[hyperref]{xcolor}		
\definecolor{MyBlue}{RGB}{50,79,132}		% für Kopf- und Fußzeile
\usepackage[colorlinks, citecolor=MyBlue, linktocpage, linkcolor=MyBlue]{hyperref}
\usepackage{color}					% Farbe
\usepackage[pdftex]{graphicx}
\usepackage{float}
\usepackage{listings}				% Programm-Code
\usepackage{longtable}				% Tabellen über mehrere Seiten
\usepackage[binary-units=true]{siunitx}				% Einheiten nach SI-Norm
\usepackage{listings}                                    % Verwendung von Matlab-Code
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage[tight]{subfigure}
\usepackage{empheq}
\usepackage{cite}
\usepackage{url}
\usepackage{framed}
\usepackage{pdfpages}
\usepackage{sidecap}
\usepackage[compact]{titlesec}
% ============================ Kopf- und Fußzeile ==========================

\pagestyle{fancy}
\fancyhf{}
\sidecaptionvpos{figure}{c}
\fancyhead[CO,CE]{\scshape\leftmark}	% Kopfzeile links [L], mitte [C], rechts [R]
\fancyfoot[RO,LE]{\thepage}				% Fußzeile
\renewcommand{\headrulewidth}{0.5pt}	% Linie oben
\renewcommand{\footrulewidth}{0pt}		% Linie unten
\pagenumbering{roman}

%============================ new Definitions ============================
\include{definitions}
\include{newChapterDefinition}
\include{titlePageDefinition}
% =============================Titelseite ==================================

\begin{document}

\pagenumbering{roman}

  \LMUTitle
      {FDTD Simulation von Elektronenstreuung an einer elektromagnetischen Welle}               % deutscher Titel der Arbeit
      {FDTD Simulation of electron scattering in an electromagnetic wave}			% english title
      {David Symhoven}                       % Vor- und Nachname des Autors
      {Witten}                             % Geburtsort des Autors
      {Computational \& Plasma Physics}                         % Name des Lehrstuhls
      {München 2017}                          % Ort und Jahr der Erstellung
      {18.07.2017}                            % Tag der Abgabe
      {Prof.Dr. Hartmut Ruhl}                          % Name des Gutachters



%======================== EINLEITUNG ========================
%===========================================================
\chapter*{Introduction}
With the increase of computational power over the last decade computer simulations became more and more attractive. Not just that it allows us to work with circumstances which are nearly impossible to create in the lab, it can also be used to make fundamental physics visible or understand the consequences of fundamental physical laws. We can use simulations to help interpret experiments or even help designing new ones. Simulations can provide detailed information about patterns and behaviors we - as humans - could never see in reality. For instance, on subatomic scales dynamics and their consequences are way too fast for us to see, like the radiation of relativistic electrons. \\
\newline
A computer simulation of $N$ interacting particles can be conducted by solving Newton's equation for each particle in the system. This is called \textit{particle-particle} approach. The main cost of computational power is the calculation of the force $\vec{F}$ acting on a particle. This requires a summation over all other particles in the system
\beq
\vec{F} = \sum_{i,j} \vec{F}_{ij} \nn,
\eeq
where $\vec{F}_{ij}$ is the interaction force of particle $i$ with particle $j$. Once the force is calculated, the underlying equation of motion can be used to calculate the velocity at a new time step and with that the new position of the particle. With the new position, the forces need to be updated and the cycle starts over. For each particle there are $N-1$ other particles to interact with. Considering that each pair interaction only needs to be calculated once, this results in a total of $\frac{N (N-1)}{2}$ calculations. For strongly coupled systems, where the number of particles is usually small compared to weakly coupled systems, this approach is feasible. For weakly coupled systems, however, where one usually has more than $10^{8}$ particles, the computational costs become too high. Even the more efficient \textit{Barnes-Hut} or \textit{tree} algorithm \cite{Barnes} which has numeric complexity of $\mathcal{O}(N \log(N))$ is not sufficient. This is where the \textit{Particle-in-Cell} (PIC) algorithm comes in. \\
\newline
PIC is the standard simulation framework for Plasma Physics today. It was \textit{Bunemann}, \textit{Dawson}, \textit{Hockney}, \textit{Birdsall} and \textit{Langdon} who promoted the development of PIC the most in the 1950's and 60's \cite{Dawson, Birdsall, Cohen}. Whereas first simulations were limited by computational power to one dimensional problems, nowadays even three dimensional simulations are feasible \cite{Fonseca, Pukhov, Bonitz}.\\
For instance, a modern super computer can achieve 100 TFLOP/s. A common simulation with $10^{8}$ particles for 10000 time steps would require about three years. The same simulation using PIC with $64 \times 64 \times 64$ cells only requires three seconds \cite{Ren}.\\
\newline
Christian Herzing developed in his PhD-thesis an hybrid field approach to improve PIC even further \cite{Herzing}. By introducing near and far fields he could reduce the numeric complexity to almost $\mathcal{O}(N)$. His framework is written in \texttt{C++}. Unfortunately this is not compatible with the \textit{Leibnitz-Rechenzentrum} (lrz) infrastructure, which requires \texttt{C} code input. So, the goal of this work is first to translate the framework into \texttt{C} and second, to build a solid and well documented code base others can build upon. To show that the framework is applicable, a real world use case, that is the scattering of an electron in a electromagnetic wave - is simulated. \\
\newline
The thesis is structured in three parts. The first part deals with the fundamentals. We present the steps of how to derive the inhomogeneous wave equation with the help of the potential equations and solve it afterwards using greens function approach.\\
In the second part the necessary numeric background is presented. We will present the underlying equations of motion and how to solve them numerically. Thereto several integration schemes are presented. We then continue to explain the hybrid field approach from Christian Herzing and the \textit{Finite Difference Time Domain} (FDTD) method, which is used to solve Maxwell Equations on a discretized grid. We then close the second part with the theory and implementation of \glqq Uniaxial Perfectly Matched Layer\grqq~which deals with the behavior of incident waves at the simulation boundary. \\
A summary and outlook is given in the third part. \\
Lastly, there is also an Appendix where some additional calculations and topics like normalization and the used software stack are covered.

%Literatur Fennel / King

%================================= acknowledgments ================
\include{acknowledgments}

%================================= SYMBOLE UND KONTANTEN ================
\include{symbols}

%================================= Inhaltsverzeichnis ==========================
\tableofcontents

%============================ Beginn Textseiten ================================
\pagenumbering{arabic}



%================================= Bildvorlage ====================================

%Code für Bildumgebung
%\begin{figure}[H]
%	\centering
%		\includegraphics[width=0.50\textwidth]{Destruktive_Interferenz.jpg} %Bild 1
%	\caption[Destruktive Interferenz]{Destruktive Interferenz \cite{[Wiki12]}}
%	\label{fig:Interferenzfilterr}
%\end{figure}
%\noindent

%===========================================================================

%======================== FUNDAMENTALS ========================
%===========================================================
\part{Fundamentals}
\noindent
In this first part we present the theoretical basics this thesis is build upon. We start with the foundation of electromagnetism - the Maxwell Equations - followed by the corresponding potential equations. Introducing Lorentz-Gauge will lead us to the inhomogeneous wave equation, which we will solve using Greens-function approach. This will lead us to the Liénard-Wiechert potentials, which are key for this thesis. Lastly, we discuss both, the non relativistic and relativistic phenomenon of energy radiation, where we restrict ourselves to the simple case where a particle is accelerated parallel to its direction of motion.
%======================== Electromagnetic radiation ========================
%===========================================================
\chapter{Electromagnetic radiation}
\section{Maxwell-Equations}
The Maxwell equations are the foundation of the classical electromagnetism theory. They describe how the electric field strength $\vec{E} \in \mathbb{R}^3$ and the magnetic field strength $\vec{H} \in \mathbb{R}^3$ are generated by charges and currents respectively and how they evolve over time in space in presence of one another. In presence of matter, however, the interaction of the fields with the material need to be taken into account. The effect of microscopic dipols, formed by bound charge carriers, are summarized in macroscopic entities called Polarisation $\vec{P} \in \mathbb{R}^3$ and Magnetization $\vec{M} \in \mathbb{R}^3$. These dipols align in the external field such that the resulting electric and magnetic field are described by
\beq
\bal
\label{eqn: materialEquationsFull}
\vec{D} &\coloneqq \epsilon_0 \vec{E} + \vec{P}\\
\vec{H} &\coloneqq \frac{1}{\mu_0} \vec{B} - \vec{M},
\eal
\eeq
where $\mu_0$ and $\epsilon_0$ are the vacuum permeability and permittivity respectively. The macroscopic Maxwell Equations than read
\beq
\label{eqn: maxwellEq}
\label{eqn: maxwell1}
\vec{\nabla} \vec{B} &=& 0\\
\label{eqn: maxwell2}
\vec{\nabla} \vec{D} &=& \rho \\
\label{eqn: maxwell3}
\vec{\nabla} \times \vec{E} &=& - \frac{\del \vec{B}}{\del t}\\
\label{eqn: maxwell4}
\vec{\nabla} \times \vec{H} &=& \frac{\del \vec{D}}{\del t} + \vec{j},
\eeq
where $\rho$ denotes the charge density of the electric source and $\vec{j}$ the electric current density. \\
In the case of vacuum, the material equations \eqref{eqn: materialEquationsFull} reduce to 
\beq
\bal
\label{eqn: materialEquations}
\vec{D} &= \epsilon_0 \vec{E}\\
\vec{H} &= \frac{1}{\mu_0} \vec{B}.
\eal
\eeq

%======================== Colomb and Lorentz Gauge ========================
\section{Colomb and Lorentz Gauge}
In the following section we consider the Maxwell Equations in vacuum. The electric and magnetic fields can also be described by a scalar and a vector potential respectively. From \eqref{eqn: maxwell1} we can conclude that 
\beq
\label{eqn: vecA}
\exists \vec{A} \in \mathbb{R}^3 \colon \vec{B} = \vec{\nabla} \times \vec{A},
\eeq
where $\vec{A}$ is called the vector potential. Plugging in \eqref{eqn: vecA} into \eqref{eqn: maxwell3} yields
\beq
\label{eqn: varphi}
\vec{\nabla} \times \left( \vec{E} + \frac{\del \vec{A}}{\del t}\right) &=& 0.\nn \\
\Rightarrow \exists \varphi \in \mathbb{R} \colon \vec{E} + \frac{\del \vec{A}}{\del t} &=& -\vec{\nabla} \varphi.
\eeq
$\varphi$ is called scalar potential. Plugging in \eqref{eqn: varphi} into \eqref{eqn: maxwell2} and also \eqref{eqn: vecA} and \eqref{eqn: varphi} into \eqref{eqn: maxwell4} gives the potential equations
\beq
\bal
\label{eqn: potentialEquations}
- \Delta \varphi - \vec{\nabla} \left(\frac{\del \vec{A}}{\del t}\right) &= \frac{\rho}{\epsilon_0} \\
\underbrace{\left(\Delta- \frac{1}{c^2}\frac{\del^2}{\del t^2}\right)}_{\coloneqq \hat\square} \vec{A} - \vec{\nabla} \left(\vec{\nabla} \vec{A} + \frac{1}{c^2}\frac{\del \varphi}{\del t}\right) &= -\mu_0\vec{j},
\eal
\eeq
where we used the \textit{Graßmann Identity}: $\vec{\nabla} \times (\vec{\nabla} \times \vec{A}) = \vec{\nabla}(\vec{\nabla}\vec{A}) - \Delta \vec{A}$.\\
The description of the fields by the aforementioned potentials $\varphi$ and $\vec{A}$ are not unique. This is called gauge freedom. The potentials can be specifically adjusted to the problem at hand. The gauge transformations look like
\beq
\bal
\vec{A} \mapsto \vec{A}' = \vec{A} + \vec{\nabla} \psi\\
\varphi \mapsto \varphi' = \varphi - \frac{\del \psi}{\del t},
\eal
\eeq
where $\psi \colon \mathbb{R}^3 \times \mathbb{R} \mapsto \mathbb{R}$. In Appendix \ref{appendix: Gauge Transformations} we show, that $\psi$ does indeed not change the physics.\\
\newline
If we choose $\psi$ such that 
\beq
\label{eqn: LaurentzGauge}
\vec{\nabla} \vec{A} + \frac{1}{c^2}\frac{\del \varphi}{\del t} = 0,
\eeq
then we call it a \textit{Lorentz Gauge} and the potential Equations \eqref{eqn: potentialEquations} decouple into two separate wave equations
\beq
\label{eqn: waveEquations}
\bal
\hat\square \varphi &= -\frac{\rho}{\epsilon_0} \\
\hat\square \vec{A} &= -\mu_0\vec{j}.
\eal
\eeq

%======================== Liénard-Wiechert Potentials ========================
\section{Liénard-Wiechert Potentials}
\label{sec: lw-potentials}
\subsection{Solution of the inhomogeneous wave equation}
The \textit{Liénard-Wiechert} Potentials are the solution of equation \eqref{eqn: waveEquations}. Following \cite{Nolting} we solve the general case
\beq
\label{eqn: generalWaveEquation}
\hat\square \psi(\vec{r}, t) = f(\vec{r},t),
\eeq
where $\psi, f: \mathbb{R}^3 \times \mathbb{R} \mapsto \mathbb{R}$. $f$ is called source function and will be specified later. \eqref{eqn: generalWaveEquation} is a linear inhomgeneous partial differential equation. Those kind of equations are solved with the \textit{Green's function} approach. If we can find the Green's function G fulfilling
\beq
\label{eqn: Greens function}
\hat\square G(\vec{r} - \vec{r}~', t - t') = - \delta(\vec{r} - \vec{r}~')\delta(t - t'),
\eeq
then we can calculate the solution of \eqref{eqn: generalWaveEquation} via
\beq
\label{eqn: WaveEquationSolution}
\psi(\vec{r}, t) = \int \int G(\vec{r} - \vec{r}', t - t') f(\vec{r},t) \dm t' ~\dm \vec{r}~'.
\eeq
To find G we use the following Fourier - Transformations 
\beq
\label{eqn: FourierTransforms}
\bal
G(\vec{r} - \vec{r}~', t - t') &= \frac{1}{4\pi^2} \int \int G(\vec{k}, \omega) \exp(i\vec{k}(\vec{r} - \vec{r}~'))\exp(-i\omega(t - t')) \dm \omega~\dm \vec{k}, \\
\delta(\vec{r} - \vec{r}~') &= \frac{1}{4\pi^2} \int \exp(i\vec{k}(\vec{r} - \vec{r}~')) \dm \vec{k}, \\
\delta(t - t') &= \frac{1}{4\pi^2} \int \exp(-i\omega(t - t')) \dm \omega.
\eal
\eeq
Plugging in \eqref{eqn: FourierTransforms} into \eqref{eqn: Greens function} yields
\beq
\int \int \exp(i\vec{k}(\vec{r} - \vec{r}~'))\exp(-i\omega(t - t')) \left[ G(\vec{k}, \omega) \left( -k^2 + \frac{\omega^2}{c^2}\right) + \frac{1}{4\pi^2} \right] = 0, \nn
\eeq
which leaves us with
\beq
G(\vec{k}, \omega) = \frac{1}{4\pi^2} \frac{1}{k^2 - \frac{\omega^2}{c^2}}. \nn
\eeq
Using residue theorem we find the Fourier Back Transform of G to be
\beq
\label{eqn: Gret}
G_{ret}(\vec{r} - \vec{r}~', t - t') = \frac{\delta(t' - t_{ret})}{4\pi |\vec{r} - \vec{r}~'|},
\eeq 
where 
\beq
t_{ret} \coloneqq t - \frac{|\vec{r} - \vec{r}~'|}{c} 
\eeq
is the retarded time. We also call $G_{ret}$ the \textit{retarded Green's function} in contrast to the \textit{advanced Green's function} $G_{av}$ with the advanced time
\beq
t_{av} \coloneqq t + \frac{|\vec{r} - \vec{r}~'|}{c}.
\eeq
The latter does not fulfill the causal principle of physics. We expect the reason for a change in our signal at $\vec{r}$ at time t, due to a perturbation, to be in the past, not the future. Because $t_{ret} < t$ the retarded Green's function is the one to work with. Plugging in \eqref{eqn: Gret} into \eqref{eqn: WaveEquationSolution} yields
\beq
\psi(\vec{r}, t) = \frac{1}{4\pi}\int \frac{f(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{r}~',
\eeq
which finally leads to the retarded potential equations
\beq
\varphi(\vec{r},t) &=& \frac{1}{4\pi \epsilon_0} \int \frac{\rho(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{r}~',\\
\vec{A}(\vec{r},t) &=& \frac{\mu_0}{4\pi} \int \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{r}~'.
\eeq
Lastly, we show in Appendix \ref{appendix: Retarded Potential Equations Fulfill Laurentz Gauge} that they indeed fulfill the Laurentz Gauge \eqref{eqn: LaurentzGauge}.

\subsection{Special Case: Moving point charge}
Now we want to discuss the special case of a particle with charge q, moving along the trajectory $\vec{r}_p$ with velocity $\vec{v} \coloneqq \dot{\vec{r}}_p$, where the dot donates the time derivative. As mentioned before, we now define the source functions for our problem at hand. For the charge density we have
\beq
\rho(\vec{r}, t) = q\delta(\vec{r} - \vec{r}_p(t))
\eeq
and for the current density
\beq
\vec{j}(\vec{r}, t) = q\vec{v}\delta(\vec{r} - \vec{r}_p(t)).
\eeq
Identifying 
\beq
\bal
\psi(\vec{r},t) &= \varphi(\vec{r},t)~\text{and}~f(\vec{r}~',t') = \frac{\rho(\vec{r}~',t')}{\epsilon_0}, \nn\\
\vec{\psi}(\vec{r},t) &= \vec{A}(\vec{r},t)~\text{and}~\vec{f}(\vec{r}~',t') = \mu_0\vec{j}(\vec{r}~',t')
\eal
\eeq
and using \eqref{eqn: WaveEquationSolution} with \eqref{eqn: Gret} yields after integrating over $\vec{r}~'$
\beq
\bal
\varphi(\vec{r},t) &= \frac{1}{4\pi \epsilon_0} \int \frac{\delta\left(\frac{ |\vec{r} - \vec{r}_p|}{c} - t + t'\right)}{|\vec{r} - \vec{r}_p|} \dm t',\\
\vec{A}(\vec{r},t) &= \frac{q \mu_0}{4\pi} \int \vec{v}(t')\frac{\delta\left(\frac{ |\vec{r} - \vec{r}_p|}{c} - t + t'\right)}{|\vec{r} - \vec{r}_p|} \dm t'.
\eal
\eeq
For the $t'$ - integration we need the following property of the $\delta$ - distribution
\beq
\delta\left[g(t')\right] = \sum_{i = 1}^{n} \frac{\delta(t' - t_i)}{\left| \left( \frac{\dm g}{\dm t'}\right)\Bigr |_{t' = t_i} \right|},
\eeq
where 
\beq
\label{eqn: gDefinition}
g(t') \coloneqq \frac{ |\vec{r} - \vec{r}_p|}{c} - t + t'
\eeq
 and $t_i$ are the roots of $g$. To find the roots of g, let's consider
\beq
\bal
\frac{\dm g}{\dm t'} &= 1+ \frac{1}{c}\frac{\dm}{\dm t'}|\vec{r} - \vec{r}_p|  = 1 - \frac{\vec{v}(t')}{c} \underbrace{ \frac{\vec{r} - \vec{r}_p}{|\vec{r} - \vec{r}_p| }}_{ |\cdot| = 1 }\\
&\Longrightarrow 1 - \frac{\vec{v}(t')}{c} \leq \frac{\dm g}{\dm t'} \leq 1 + \frac{\vec{v}(t')}{c} \\
&\stackrel{v < c}{\Longrightarrow} \frac{\dm g}{\dm t'} > 0,
 \eal
\eeq
which means that $g$ is a monotonically increasing function and therefore has at most one root, which is $t' = t_{ret}$ as can be seen from \eqref{eqn: gDefinition}. In case that g has no roots at all, we can conclude that $\varphi \equiv 0$ and $\vec{A} \equiv 0$.\\
With $t_{ret} \coloneqq t - \frac{|\vec{r} - \vec{r}_p|}{c} $ the integration over $t'$ yields
\beq
\bal
\varphi(\vec{r},t) &= \frac{1}{4\pi \epsilon_0}\frac{q}{|\vec{r} - \vec{r}_p(t_{ret})| - \frac{\vec{v}(t_{ret})}{c}(\vec{r} - \vec{r}_p(t_{ret}))},\\
\vec{A}(\vec{r},t) &= \frac{1 \mu_0}{4\pi} \frac{q\vec{v}(t_{ret})}{|\vec{r} - \vec{r}_p(t_{ret})| - \frac{\vec{v}(t_{ret})}{c}(\vec{r} - \vec{r}_p(t_{ret}))}
\eal
\eeq
which are the \textit{Liénard-Wiechert} Potentials. Upon defining 
\beq
\bal
\vec{\beta}(t) &\coloneqq \frac{\vec{v}(t)}{c},\\
\vec{R}(\vec{r},t) &\coloneqq \vec{r} - \vec{r}_p(t),\\
\vec{n}(\vec{r},t) &\coloneqq \frac{\vec{R}(\vec{r},t)}{R(\vec{r},t)}
\eal
\eeq
we can rewrite the Liénard-Wiechert Potentials in a more compact and final form
\beq
\bal
\label{eqn: LWPotentials}
\varphi(\vec{r},t) &= \frac{1}{4\pi \epsilon_0}\frac{q}{(1 - \vec{\beta}(t') \cdot \vec{n}(\vec{r},t')) R(\vec{r},t')}\Biggr |_{t' = t_{ret}},\\
\vec{A}(\vec{r},t) &= \frac{\mu_0}{4\pi} \frac{q\vec{\beta}(t')}{(1 - \vec{\beta}(t') \cdot \vec{n}(\vec{r},t')) R(\vec{r},t')}\Biggr |_{t' = t_{ret}}.
\eal
\eeq
The latter potentials are the generalization of the Coulomb Potential. With the help of \eqref{eqn: varphi} the electric and magnetic fields can be derived from the \textit{Liénard-Wiechert} Potentials \eqref{eqn: LWPotentials}. Since this is a quite longish calculation it is refered to \cite{Nolting} and just present the final result 
\beq
\label{eqn: Liénard-Wiechert}
\bal
\vec{E}(\vec{r}, t) &= \frac{q}{4\pi \epsilon_0} \left( \frac{\vec{n}(\vec{r},t') - \vec{\beta}(t)}{ \gamma^2(1 - \vec{\beta}(t) \cdot \vec{n}(\vec{r},t'))^3 R^2(\vec{r},t')} \right. \\
& \left. + \frac{1}{c} \frac{\vec{n}(\vec{r},t') \times (\vec{n}(\vec{r},t') - \vec{\beta}(t)) \times \dot{\vec{\beta}}(t)}{(1 - \vec{\beta}(t) \cdot \vec{n}(\vec{r},t'))^3 R(\vec{r},t')}\right)\Biggr |_{t' = t_{ret}}, \\
\vec{B}(\vec{r}, t) &= \frac{1}{c} \left(\vec{n}(\vec{r},t') \times \vec{E}(\vec{r}, t)\right)\Biggr |_{t' = t_{ret}}.
\eal
\eeq
This is the electric and magnetic field of a moving charged particle. Due to the finite speed of light, the fields need time to travel from their source to the observation point. That means, that the fields at time $t$, were actually produced at a earlier time $t_{ret}$. As can be seen in Figure \ref{fig: Interpolation}, the retarded time is determined by the intersection point of the particle trajectory with the backward lightcone of the observation point.\\

\subsection{Energy emission}
\label{sec: Energy emission}
Now we want to discuss the energy flow and emission. Therefore, we need to analyze the Poynting Vector
\beq
\label{eqn: PoyntingVector}
\vec{S} = \frac{1}{\mu_0}\vec{E} \times \vec{B} =  \frac{1}{\mu_0 c} \left[ \vec{n}_{ret} E^2  - \left(\vec{n}_{ret} \vec{E}\right) \vec{E}\right],
\eeq
where $\vec{n}_{ret} \coloneqq \vec{n}(\vec{r}, t_{ret})$. Taking a closer look at \eqref{eqn: Liénard-Wiechert} reveals that both $\vec{E}$ and $\vec{B}$ can be separated into two parts, one of which is not dependent on the particle acceleration 
\beq
\bal
\label{eqn: Ev}
\vec{E}_{(v)}(\vec{r}, t) &= \frac{q}{4\pi \epsilon_0} \frac{1}{ \gamma^2(1 - \vec{\beta}(t') \cdot \vec{n}(\vec{r},t'))^3 R^2(\vec{r},t')} \left(\vec{n}(\vec{r},t') - \vec{\beta}(t')\right)\Biggr|_{t' = t_{ret}}\\
\vec{B}_{(v)}(\vec{r}, t) &= \frac{q}{4\pi \epsilon_0 c} \frac{1}{ \gamma^2(1 - \vec{\beta}(t') \cdot \vec{n}(\vec{r},t'))^3 R^2(\vec{r},t')} \underbrace{\left[\vec{n} \times \left(\vec{n}(\vec{r},t') - \vec{\beta}(t')\right)\right]}_{= \frac{1}{c}\left(\vec{v} \times \vec{n}\right)}\Biggr|_{t' = t_{ret}} 
\eal
\eeq
whilst the other is through $\dot{\vec{\beta}}$
\beq
\bal
\label{eqn: Ea}
\vec{E}_{(a)}(\vec{r}, t) &= \frac{q}{4\pi \epsilon_0c}  \frac{\vec{n}(\vec{r},t') \times \left(\vec{n}(\vec{r},t') - \vec{\beta}(t')\right) \times \dot{\vec{\beta}}(t')}{\left(1 - \vec{\beta}(t') \cdot \vec{n}(\vec{r},t')\right)^3 R(\vec{r},t')}\Biggr |_{t' = t_{ret}}\\
\vec{B}_{(a)}(\vec{r}, t) &= \frac{q}{4\pi \epsilon_0c^2} \frac{\vec{n}(\vec{r},t') \times \left[\vec{n}(\vec{r},t') \times \left(\vec{n}(\vec{r},t') - \vec{\beta}(t')\right) \times \dot{\vec{\beta}}(t')\right]}{\left(1 - \vec{\beta}(t') \cdot \vec{n}(\vec{r},t')\right)^3 R(\vec{r},t')}\Biggr |_{t' = t_{ret}}.
\eal
\eeq
Since $E_{(v)} \propto \frac{1}{R^2}$ whereas $E_{(a)} \propto \frac{1}{R}$, its field contributions will dominate in the far field, i.e. for large distances from the source. Plugging in \eqref{eqn: Liénard-Wiechert} in \eqref{eqn: PoyntingVector} gives us several terms with different orders of $\frac{1}{R}$, namely
\beq
\bal
\vec{S}_{vv} &\propto \left| \vec{E}_{(v)} \times \vec{B}_{(v)} \right| \propto \frac{1}{R^4},\\
\vec{S}_{va} &\propto \left| \vec{E}_{(v)} \times \vec{B}_{(a)} \right| \propto \frac{1}{R^3},\\
\vec{S}_{aa} &\propto \left| \vec{E}_{(a)} \times \vec{B}_{(a)} \right| \propto \frac{1}{R^2}. \nn
\eal
\eeq
By evaluating the energy flux through an arbitrary surface with differential surface area $\dm\vec{\sigma}$, as illustrated in Figure \ref{fig: PoyntingVector},
\begin{figure}[H]
	\centering
		\includegraphics[width=0.50\textwidth]{Pictures/PoyntingVector.png}
	\caption[Illustration of how to calculate the energy emission of a moving particle with charge $q$.]{Illustration of how to calculate the energy emission of a moving particle with charge $q$. \cite{Nolting}}
	\label{fig: PoyntingVector}
\end{figure}
\noindent
we can see, that it will suffice to only consider the $\frac{1}{R^2}$ terms, because the $\frac{1}{R^3}$ or higher terms do not contribute to the energy emission, since
\beq
\oint \vec{S} \dm\vec{\sigma} \rightsquigarrow \oint \frac{1}{R^3} r^2 \dm\Omega \rightsquigarrow \oint \frac{1}{r} \dm\Omega \rightsquigarrow \frac{1}{r} \stackrel{r \rightarrow \infty}{\longrightarrow} 0,
\eeq
where $\dm\Omega \coloneqq \sin(\vartheta)\dm\vartheta\dm\varphi$. That means we can focus on $\eqref{eqn: Ea}$ when calculating $\eqref{eqn: PoyntingVector}$
\beq
\vec{S} =  \frac{1}{\mu_0 c} \frac{q^2}{16\pi^2 \epsilon_0^2 c^2}  \frac{\vec{n}(\vec{r},t') \left[\vec{n}(\vec{r},t') \times \left(\vec{n}(\vec{r},t') - \vec{\beta}(t')\right) \times \dot{\vec{\beta}}(t')\right]^2}{\left(1 - \vec{\beta}(t') \cdot \vec{n}(\vec{r},t')\right)^6 R^2(\vec{r},t')}\Biggr |_{t' = t_{ret}} + \mathcal{O}\left(\frac{1}{R^3}\right).
\eeq
The energy flux has the direction of $\vec{n}_{ret}$, i.e. it flows from the particle position $\vec{r}_p$ at time $t' = t_{ret}$ to the observation point $\vec{r}$. We can also see, that only accelerated particles ($\dot{\vec{\beta}} \neq 0$) loose energy through radiation, which leads to a reduction in kinetic energy. Although an uniformly moving particle produces E and B - fields, it does not loose energy through radiation.\\
\newline
Lastly, we want to discuss the radiation power. The emitted energy per time $\dm t$ into the solid angle $\dm \Omega$ is described by
\beq
\frac{\dm W}{\dm \Omega} = \left( \vec{S} \cdot \vec{n}(\vec{r}, t') \right) R^2(\vec{r}, t')\Bigr |_{t' = t_{ret}}.
\eeq
Usually the observed amount of energy per unit time $\dm t$ is not the same as the emitted energy of the particle per unit time $\dm t_{ret}$. To learn more about the emission within the particles system, we want to express our equation in terms of $\dm t_{ret}$, which gives us
\beq
\frac{\dm W}{\dm \Omega} = \left( \vec{S} \cdot \vec{n}(\vec{r}, t') \right) R^2(\vec{r}, t') \left(\frac{\dm t}{\dm t'}\right)\Bigr |_{t' = t_{ret}}.
\eeq
From the definition of $t_{ret} \coloneqq t' - \frac{|\vec{r} - \vec{r}~'|}{c}$ we find
\beq
\left(\frac{\dm t}{\dm t'}\right)\Bigr |_{t' = t_{ret}} = \left(1 + \frac{1}{c} \frac{\dm}{\dm t'} |\vec{r} - \vec{r}_p(t')|\right)\Bigr |_{t' = t_{ret}} = \left(1 - \frac{1}{c} \vec{n}(\vec{r}, t')\vec{v}(t')\right)\Bigr |_{t' = t_{ret}}.
\eeq
Finally, we obtain
\beq
\label{eqn: RadiationPower}
\frac{\dm W}{\dm \Omega} =  \frac{q^2}{16\pi^2 \epsilon_0 c}  \frac{ \left[\vec{n}(\vec{r},t') \times \left(\vec{n}(\vec{r},t') - \vec{\beta}(t')\right) \times \dot{\vec{\beta}}(t')\right]^2}{\left(1 - \vec{\beta}(t') \cdot \vec{n}(\vec{r},t')\right)^5} \Biggr |_{t' = t_{ret}}.
\eeq
Now we can discuss two cases. The non relativistic case ($\beta \approx 0$) and the relativistic case ($\beta \approx 1$).\\
\begin{description}
\item[$\beta \approx 0$:] In this case \eqref{eqn: RadiationPower} simplifies to
\beq
\bal
\frac{\dm W}{\dm \Omega} &=  \frac{q^2}{16\pi^2 \epsilon_0 c}   \left[\vec{n}(\vec{r},t') \times \left(\vec{n}(\vec{r},t') \times \dot{\vec{\beta}}(t')\right)\right]^2 \Biggr |_{t' = t_{ret}} \\
&=  \frac{q^2}{16\pi^2 \epsilon_0 c}   \left[\underbrace{\left(\vec{n}(\vec{r},t') \cdot \dot{\vec{\beta}}(t') \right)}_{= \dot{\beta}n\cos(\vartheta)} \vec{n}(\vec{r},t') - \underbrace{\left(\vec{n}(\vec{r},t') \cdot \vec{n}(\vec{r},t')\right)}_{ |\cdot| = 1} \dot{\vec{\beta}}(t')\right]^2 \Biggr |_{t' = t_{ret}} \\
& = \frac{q^2\dot{\beta}^2_{ret}}{16\pi^2 \epsilon_0 c}  \left(\cos^2(\vartheta) - 2\cos^2(\vartheta) + 1\right)\\
&=  \frac{q^2 \dot{\beta}^2_{ret}}{16\pi^2 \epsilon_0 c} \sin^2(\vartheta) \nn,
\eal
\eeq 
where $\vartheta$ is the angle between $\dot{\vec{\beta}}$ and $\vec{n}$. $\beta_{ret}$ means again the evaluation at $t' = t_{ret}$. We conclude that the direction of maximum radiation is perpendicular to the particles direction of motion, in contrast to
\item[$\beta \approx 1$:] where we will see shortly that the maximum radiation will be primarily in the direction of motion of the particle. We will restrict ourselves to the simple case, where $\dot{\vec{\beta}} \parallel \vec{\beta}$. Following the same steps as above we obtain
\beq
\frac{\dm W}{\dm \Omega} = \frac{q^2 \dot{\beta}^2_{ret}}{16\pi^2 \epsilon_0 c} \frac{\sin^2(\vartheta)}{\left(1 - \beta(t')\cos(\vartheta)\right)^5}.
\eeq
To get the angle, where the radiation is maximal, we calculate
\beq
\bal
\frac{\dm}{\dm(\cos(\vartheta))} &\left(\frac{\dm W}{\dm \Omega}\right) \stackrel{!}{=} 0 \\
\Longleftrightarrow& -2\cos(\vartheta)\left(1-\beta_{ret}\cos(\vartheta)\right)^5 + 5\beta_{ret}(1-\cos^2(\vartheta))\left(1-\beta_{ret}\cos(\vartheta)\right)^4 \stackrel{!}{=} 0 \\
\Longleftrightarrow& \left(1-\beta_{ret}\cos(\vartheta)\right)^4 \left[-2\cos(\vartheta)\left(1-\beta_{ret}\cos(\vartheta)\right) + 5\beta_{ret}(1-\cos^2(\vartheta))\right] \stackrel{!}{=} 0 \\
\Longrightarrow& -2\cos(\vartheta)\left(1-\beta_{ret}\cos(\vartheta)\right) + 5\beta_{ret}(1-\cos^2(\vartheta)) \stackrel{!}{=} 0 \\
\Longleftrightarrow& \cos^2(\vartheta) + \frac{2}{3\beta_{ret}}\cos(\vartheta) - \frac{5}{3} \stackrel{!}{=} 0\\
\Longrightarrow& \cos(\vartheta)_{max} = \frac{1}{3\beta_{ret}}\left(\sqrt{1+15\beta_{ret}^2} -1\right).\nn
\eal
\eeq
Obviously the angle decreases monotonically with increasing velocity, i.e. increasing $\beta_{ret}$. For $\beta_{ret} = 1$ we get $\cos(\vartheta) = 1$ or equivalently $\vartheta = 0$. In Figure \ref{fig: radiationSummary} the results are summarized.
 \begin{figure}[H]
	\centering
		\includegraphics[width=0.50\textwidth]{Pictures/RadiationSummary.png}
	\caption[Radiation characteristics of an moving charged particle]{Radiation characteristics of an moving charged particle. \cite{Nolting}}
	\label{fig: radiationSummary}
\end{figure}
\noindent
\end{description}
 
%======================== NUMERICS ========================
%===========================================================
\part{Numerics}
\noindent
The following section deals with the numeric aspects of this thesis. We explain the underlying equation of motions and their history. After that, we go into several methods with which we can solve differential equations. Over the course of the last decades numerous methods were invented each of which has its own strengths and weaknesses. 
Some of them are very easy to implement, which in turn usually leads to unprecise results. Others are quite complicated and sophisticated to implement, but very accurate.
Therefore, one should always consider which method is best for the problem and what it is one want to achieve.\\
Following this, we also want to define and calculate the numerical complexity of some chosen algorithms. 

%======================== Integration of equation of motion ========================
%===========================================================
\chapter{Integration of Equation of Motion}
%======================== Equations of Motion ========================
\section{Equations of Motion}
\label{sec: Equations of Motion}
As we know from mechanics the dynamics of particles is determined by the forces acting on them. In our case there is a force due to electro-magnetic fields. That can be external fields, but also fields due to moving particles, as we explained in Section \ref{sec: lw-potentials}.\\
The dynamics of our system is described by the \textit{Lorentz-Newton} equations
\beq
\label{eqn: Lorentz-Newton}
\bal
\frac{\dm x^{\mu}}{\dm \tau} &= u^{\mu}\\
\frac{\dm u^{\mu}}{\dm \tau} &= F^{\mu}_{~\nu}~u^{\nu} + g^{\mu}.
\eal
\eeq
The term $F^{\mu}_{~\nu}$ describes the electromagnetic field strength tensor
\beq
F^{\mu}_{~\nu} = 
\begin{pmatrix}
0 & E_x & E_y & E_z \\
E_x & 0 & B_z & -B_y \\
E_y & -B_z & 0 & B_x \\
E_z & B_y & -B_x & 0
\end{pmatrix}
.
\eeq
The damping term $g^{\mu}$ considers the fact that charged particles radiate fields when they are moving which leads to a loss in their kinetic energy. Within the context of classical electrodynamics Max \textit{Abraham} and Hendrick \textit{Lorentz} discussed radiation damping in their same-named equation first.
In 1938 \textit{Dirac} generalized the equation whilst taking special relativity into account \cite{Dirac}. It turned out, however, that this equation has unphysical solutions, which violate the causality principle. \textit{Landau} and \textit{Lifschitz} solved this problem using perturbation theory \cite{Landau}. The Landau-Lifschitz equation reads
\begin{multline}
\label{eqn: Landau-Lifschitz}
g^{\mu} = \frac{\mu_0q^2}{6\pi c}\biggl(\frac{q}{m_e}\frac{\del F^{\mu\nu}_{\quad \text{ext}}}{\del x^{\xi}}u^{\nu}u^{\xi} - \frac{e^2}{m^{2}_e}F^{\mu\xi}_{\quad \text{ext}}F_{\nu\xi~\text{ext}}u^{\nu} \\
+\frac{q^2}{m^{2}_ec^2}(F_{\nu\xi~\text{ext}}u^{\xi})(F^{\nu\pi}_{\quad \text{ext}}u_{\pi})u^{\mu}\biggr).
\end{multline}
In this thesis the damping term $g^{\mu}$ is neglected. In \cite{Jackson} a rough estimation shows that radiation damping of an electron gyrating in a constant $B$ field with frequency $\omega_0$ can be neglected if 
\beq
\label{eqn: damping estimation}
\omega_0 \Delta \tilde{t} \ll 1
\eeq
holds. $\Delta \tilde{t} = \frac{q^2}{4\pi\epsilon_0m_ec^3} = 9.40 \cdot 10^{-24}\si{\second}$ is the normalized time. In Section \ref{sec: electron scattering} we show, that equation \eqref{eqn: damping estimation} is indeed fulfilled in our simulations. \\
We now want to present different methods of how to solve the Lorentz-Newton equation \eqref{eqn: Lorentz-Newton} numerically.

%======================== Euler Scheme ========================
\section{Euler-Scheme}
The most simple method is the explicit \textit{Euler}-Method. It's easy to implement but not very accurate, as we shall see later. But before we go into the details of the explicit Euler-Scheme we need to address some prerequisites all following methods will have in common. \\
Starting point will always be a first order system of the kind
\beq
\label{eqn: Euler}
\bal
\frac{\dm x^{\mu}}{\dm \tau} &= u^{\mu}\\
\frac{\dm u^{\mu}}{\dm \tau} &= f^{\mu}(x^{\nu},u^{\nu})\\
x^{\mu}(\tau_0) &= x^{\mu}_0\\
u^{\mu}(\tau_0) &= u^{\mu}_0.
\eal
\eeq
Systems of higher order can always be reduced to a first order system. \\
In order to solve the equation of motion numerically the domain needs to be discretized. Therefore, we divide the time interval into N equidistant partial intervals $h$, by defining
\beq
h \coloneqq \Delta \tau = \tau_{i+1} - \tau_i. \nn
\eeq
The idea is to calculate each point along the trajectory $x^{\mu}_i = x^{\mu}(\tau_i)$ iteratively, starting from the initial values $x^{\mu}_0$ and $u^{\mu}_0$.
But to calculate these points all differential operators in  \eqref{eqn: Euler} need to be discretized as well. That is where all methods differ. Each method has its own way to discretize the differential operators.\\
The basis of the Euler-Scheme is a first order Taylor expansion of the integration variable $x^{\mu}$ in $\tau$ around $\tau_i$
\beq
\label{eqn: Taylor}
x^{\mu}(\tau_{i+1}) =  x^{\mu}(\tau_i) + \frac{\dm x^{\mu}}{\dm \tau} \Big |_{\tau=\tau_i} \underbrace{(\tau_{i+1} - \tau_i)}_{=h} + \mathcal{O}(h^2).
\eeq
Analogously for $u^{\mu}$ and solving for  $\frac{\dm x^{\mu}}{\dm \tau}$ and $\frac{\dm u^{\mu}}{\dm \tau}$ respectively yields
\beq
\bal
\frac{x^{\mu}_{i+1} - x^{\mu}_i}{h} &= u^{\mu}_i\\
\frac{u^{\mu}_{i+1} - u^{\mu}_i}{h} &= f^{\mu}(x^{\nu}_i,u^{\nu}_i).
\eal
\eeq
This way of discretizing allows a very easy calculation of $x^{\mu}_i$ according to
 \beq
\bal
x^{\mu}_{i+1} &= x^{\mu}_i + h~u^{\mu}_i\\
u^{\mu}_{i+1} &= u^{\mu}_i + h~f^{\mu}(x^{\nu}_i,u^{\nu}_i).
\eal
\eeq
In order for us to calculate the goodness of this approximation we need to introduce the \textit{Procedural Error} and the \textit{Order of Consistency} \cite{NumerikSkript}.\\
\subsection{Procedural Error  and Order of Consistency}
\newtheorem{env_definition}{Definition}[section]
\begin{env_definition}[Procedural Error  and Order of Consistency]
\label{def: Procedural Error}
Let $I \subseteq \mathbb{R}$ be a interval, $f : I \times \mathbb{R}^d \to \mathbb{R}^d$, $y : I \to \mathbb{R}^{d}$ a solution of the initial value problem
\beq
\bal
\frac{\dm}{\dm \tau}y(\tau) &= f(\tau,y(\tau)),\\
y(\tau_0) &= y_0. 
\eal
\eeq
\begin{description}
\item[(a)] The term 
\beq
\eta(\tau,h) \coloneqq y(\tau) + h f(\tau, y(\tau)) - y(\tau+h)\quad \text{for}~\tau \in I,~ 0 < h \le b - \tau
\eeq
is called local Procedural Error of the One-Step-Scheme at $\tau$ for the increment h.
\item[(b)] The One-Step-Scheme has an Order of Consistency $p \ge 1$, if the local Procedural Error fulfils
\beq
||\eta(\tau,h) || \le Ch^{p+1}\quad \text{for}~\tau \in I,~ 0 < h \le b - \tau,
\eeq 
with a constant $C\ge 0$, which is independent of $\tau$ and $h$.
\end{description}
\end{env_definition}
Descriptively the Procedural Error is the difference between the exact solution $y(\tau+h)$ and the result, which we get from the One-Step-Scheme starting from the exact solution at the earlier time step $y(\tau)$.
Figure \ref{fig: Procedural Error} illustrates the situation.
\begin{figure}[H]
	\centering
		\includegraphics[width=0.50\textwidth]{Pictures/Verfahrensfehler.png} %Bild 1
	\caption[Procedural Error]{Illustration of the Procedural Errors of an One-Step-Scheme.~ \cite{NumerikSkript}}
	\label{fig: Procedural Error}
\end{figure}
\noindent
We now want to use the definitions \ref{def: Procedural Error} to calculate the Order of Consistency of the Euler-Scheme.\\
Starting point is the system \eqref{eqn: Lorentz-Newton}. Thereby we focus on the equation for $u^{\mu}$, since $x^{\mu}$ can be easily integrated from $u^{\mu}$.
Following Definition \ref{def: Procedural Error} we have
\beq
y = u^{\mu}. \nn \\
\eeq
We get
\beq
\label{eqn: eta u}
\eta(\tau, h) = u^{\mu}(\tau_i) + h f^{\mu}(x^{\nu}, u^{\nu}) - u^{\mu}(\tau_{i+1}).
\eeq
The last term can be calculated with a Taylor-expansion analogously to \eqref{eqn: Taylor}.
\beq
\label{eqn: Taylor u}
u^{\mu}(\tau_{i+1}) =  u^{\mu}(\tau_i) + h~\frac{\dm u^{\mu}}{\dm \tau} \Big |_{s=\tau_i}  + h^2~\frac{\dm^2 u^{\mu}}{\dm \tau^2} \Big |_{s=\tau_i}.
\eeq
Plugging in \eqref{eqn: Taylor u} in \eqref{eqn: eta u} yields
\beq
\bal
\eta(\tau, h) &= u^{\mu}(\tau_i) + h\frac{\dm u^{\mu}}{\dm \tau}  - u^{\mu}(\tau_{i+1}) \\
\stackrel{ \eqref{eqn: Taylor u}}{\Longrightarrow}\eta(\tau, h) &= u^{\mu}(\tau_i) + h\frac{\dm u^{\mu}}{\dm \tau}  - u^{\mu}(\tau_i) - h\frac{\dm u^{\mu}}{\dm \tau} - h^2\frac{\dm^2 u^{\mu}}{\dm \tau^2}\\
\Longleftrightarrow\eta(\tau, h) &= \frac{\dm^2 u^{\mu}}{\dm \tau^2}~h^2 ,
\eal
\eeq
since $\frac{\dm u^{\mu}}{\dm \tau} = f^{\mu}(x^{\nu}, u^{\nu})$ holds for the Euler-Scheme. Thus
\beq
|\eta(\tau, h)| \le C h^2 \quad \text{with}~C \coloneqq \frac{1}{2} \max_{\tau \in \mathcal{D}(u^{\mu})}\left| \frac{\dm^2 u^{\mu}}{\dm \tau^2}\right|.
\eeq
$\mathcal{D}(u^{\mu})$ denotes the domain of $u^{\mu}$. Therefore, the Euler-Scheme has an Order of Consistency of one.


%======================== Leap Frog Scheme ========================
\section{Leap-Frog-Scheme}
A definitely better method is the so called \textit{Leap-Frog}-Scheme. One can easily proof that it has an Order of Consistency of two. \\
In contrast to the explicit Euler-Scheme this method has several advantages. For one, it is time reversible, i.e. it is possible to reach any previous point in time from every point later in the trajectory. On the other hand, the Leap-Frog-Scheme is symplectic, meaning it conserves the phase space volume from which energy and momentum conservation follows. \\
However, one disadvantage is that it's only suited for systems in which the acting force exclusively depends on the current position, but not on the velocity of the particle. This would lead to an implicit equation system which is numerically way more expensive to solve. \\
Thus the differential equation should be of the form
\beq
\frac{\dm^2 x^{\mu}}{\dm \tau^2} = \frac{\dm u^{\mu}}{\dm \tau} = f^{\mu}(x^{\nu}).
\eeq
As we already mentioned, the various methods discretize the differential operators differently.
The Leap-Frog-Scheme uses
\beq
\bal
\frac{x^{\mu}_{i+1} - x^{\mu}_i}{h} &= u^{\mu}_{i+\frac{1}{2}}\\
\frac{u^{\mu}_{i+\frac{1}{2}} - u^{\mu}_{i-\frac{1}{2}}}{h} &= f^{\mu}(x^{\nu}_i).
\eal
\eeq
Solving for the new time step yields
\beq
\bal
x^{\mu}_{i+1} &= x^{\mu}_i + h u^{\mu}_{i+\frac{1}{2}}\\
u^{\mu}_{i+\frac{1}{2}} &= u^{\mu}_{i-\frac{1}{2}} + h f^{\mu}(x^{\nu}_i).
\eal
\eeq
\noindent
As we can see, position and velocity are calculated at different times. They are shifted against each other in time by $h = \frac{1}{2}$. \\
But what if we have a system in which the force depends on the velocity? Are we stuck with expensive implicit methods? Fortunately not. We can use the \textit{Boris} - Method.
\subsection{Boris-Method}
\label{sec: Boris-Method}
This method was invented in 1970 by J.P. Boris \cite{boris} and is the standard method for pushing particles in plasma simulations today. We want to solve the Lorentz-Newton equation
\beq
\label{eqn: LorentzNewton}
\bal
\frac{v_{i+\frac{1}{2}} - v_{i - \frac{1}{2}}}{h} &= \frac{q}{m}\left(\vec{E} + \frac{v_{i+\frac{1}{2}} + v_{i - \frac{1}{2}}}{2} \times \vec{B}\right)
\eal
\eeq
Boris noticed, that upon defining
\beq
\label{eqn:vMinusAndPlus}
\bal
\vec{v}_{-} &\coloneqq v_{i - \frac{1}{2}} + \frac{h}{2}\frac{q \vec{E}}{m}\quad\text{and} \\
\vec{v}_{+} &\coloneqq v_{i + \frac{1}{2}} + \frac{h}{2}\frac{q \vec{E}}{m},
\eal
\eeq
one can eliminate the electric field. Plugging in \eqref{eqn:vMinusAndPlus} into \eqref{eqn: LorentzNewton} yields
\beq
\bal
\label{eqn: v+}
\frac{\vec{v}_{+} - \vec{v}_{-}}{h} &= \frac{q}{m} (\vec{v}_{+} + \vec{v}_{-}) \times \vec{B}\\
\Longrightarrow  |\vec{v}_{+} - \vec{v}_{-}| &= \frac{qh}{m} |\vec{v}_{+} + \vec{v}_{-}| B \underbrace{\sin(\vartheta)}_{= 1},
\eal
\eeq
where $\vartheta$ is the angle between $\vec{B}$ and $\vec{v}$. By splitting up the accelerating effect of the electric field in two parts with the rotational effect of the magnetic field in between, the accuracy is increased without having computational overhead.  Hence, the steps are
\begin{enumerate}
\item Obtain $\vec{v}_{-}$ by starting from $v_{i - \frac{1}{2}}$ and adding half electric impulse.
\item Use rotation in \eqref{eqn: v+} to obtain $\vec{v}_{+}$ and finally
\item obtain $v_{i + \frac{1}{2}}$ by adding yet another half electric impulse.
\end{enumerate}
\noindent
In the code used in this master thesis, the slightly more sophisticated but relativistically correct form with $u = \gamma v$ is used. \\
Up to now one question remains unanswered. How do we solve for $\vec{v}_{+}$ in \eqref{eqn: v+}? To answer this, we use Figure \ref{fig: borisProjection}.
\begin{figure}[H]
	\centering
		\includegraphics[width=0.50\textwidth]{Pictures/borisProjection.png} 
	\caption[Velocity space showing the rotation from $\vec{v}_{-}$ to $\vec{v}~'$]{Velocity space showing the rotation from $\vec{v}_{-}$ to $\vec{v}~'$. The velocities shown are projections of the total velocities onto the plane perpendicular to $\vec{B}$. ~\cite{Birdsall}}
	\label{fig: borisProjection}
\end{figure}
\noindent
What we want is a vector, which is parallel to $\vec{v}_{+} - \vec{v}_{-}$. Its magnitude is yet to be determined. However, if we can find a vector $\vec{v}~'$ which is perpendicular to $\vec{v}_{+} - \vec{v}_{-}$, then $\vec{v}~' \times \vec{s}$, where $\vec{s} \propto \vec{B}$, is exactly what we need.\\
Upon defining
\beq
\vec{t} \coloneqq -\frac{\vec{B}}{B} \tan\left(\frac{\theta}{2}\right) = \frac{q\vec{B}h}{2m},
\eeq
we obtain $\vec{v}~'$ from
\beq
\vec{v}~' = \vec{v}_{-} + \vec{v}_{-} \times \vec{t}.
\eeq
Now $\vec{v}~' $ is perpendicular to  $\vec{v}_{+} - \vec{v}_{-}$. Finally, we need a vector $\vec{s} \propto \vec{B}$ wich magnitude is determined by the constraint $|\vec{v}_{+}|= |\vec{v}_{-}|$. Using half angle formulas we find 
\beq
\vec{s} = \frac{2\vec{t}}{1+t^2}.
\eeq
Hence,
\beq
\vec{v}_{+}= \vec{v}_{-} + \vec{v}~' \times \vec{s}.
\eeq
Finally, we want to do a quick error analysis. We expect the angle of rotation $\theta$ to be close to 
\beq
\omega_ch = \frac{2\pi h}{T} = \frac{qBh}{m},\nn
\eeq
where T is the period.\\
Following the geometrical analysis in ~\cite{Birdsall} illustrated in \ref{fig: borisRotation} and using \eqref{eqn: v+} we find
\beq
\bal
\left|\tan\left(\frac{\theta}{2}\right)\right| &= \frac{\frac{1}{2}|\vec{v}_{+} - \vec{v}_{-}|}{\frac{1}{2}|\vec{v}_{+} + \vec{v}_{-}|} = \frac{qB }{m} \frac{h}{2} = \frac{\omega_c h}{2}\\
\Longrightarrow \theta &= 2\arctan\left(\frac{\omega_c h}{2}\right) = \omega_c h \left(1 - \frac{\omega^2_c h^2}{12} + \ldots \right).
\eal
\eeq
For $\omega_ch < 0.35$ we get an error smaller than $1\%$.
\begin{figure}[H]
	\centering
		\includegraphics[width=0.50\textwidth]{Pictures/borisRotation.png} 
	\caption[Determination of $\left|\tan\left(\frac{\theta}{2}\right)\right|$ from boris roation]{Determination of $\left|\tan\left(\frac{\theta}{2}\right)\right|$ from boris rotation~\cite{Birdsall}}
	\label{fig: borisRotation}
\end{figure}
\noindent

%======================== Interpolations ========================
%===========================================================
\chapter{Interpolations}

%======================== Linear interpolation of Trajectories ========================
\section{Linear interpolation of Trajectories}
\label{sec: Interpolation of Trajectories}
The previously presented methods calculate the particle trajectory solely at discrete points in time $x_i^{\mu}(\tau)$. Calculating Liénard-Wiechert fields according to equation \eqref{eqn: Liénard-Wiechert} , however, requires the intersection point of the trajectory with the backward lightcone of the observation point. 
In most cases the calculated points of the trajectory are not lying directly on the lightcone, so we need a procedure to calculate the intersection point exactly.\\
The simplest solution is a linear interpolation between the last point inside and the first point outside the lightcone. Figure \ref{fig: Interpolation} illustrates the situation.
\begin{figure}[t]
	\centering
		\includegraphics[width=0.80\textwidth]{Pictures/LightconeNew.pdf}
	\caption[Interpolation of Trajectories]{Minkowski space showing the particle trajectory with starting point $x^{\mu}_0(t_0)$ and last point $x^{\mu}_N(t)$. The observation point $x^{\mu}_o(t)$ with its backward lightcone is also shown. If we want to calculate the Liénard-Wiechert fields at the observation point $x^{\mu}_o(t)$, we need the intersection point $x^{\mu}_c(t_{ret})$ of the trajectory with the backward lightcone. }
	\label{fig: Interpolation}
\end{figure}
\noindent
Thereto let $x_j^{\mu} \in \mathbb{R}^{3+1}$ be the last point inside and $x_{j+1}^{\mu} \in \mathbb{R}^{3+1}$ the first point outside the lightcone. Further let $x_{c}^{\mu} \in \mathbb{R}^{3+1}$ be the intersection point of interest then we get
\beq
\label{eqn: linInt}
x_c^{\mu} = x_j^{\mu} + \lambda ~\left(x_{j+1}^{\mu} - x_j^{\mu}\right),
\eeq
where $\lambda \in [0,1]$. Due to the finite speed of light the intersection point $x_c^{\mu}$ needs to fulfill
\beq
\label{eqn: constraint}
\left| \vec{x}_o(t) - \vec{x}_c(t_{ret})\right| = c~(t - t_{ret}) \Longleftrightarrow (x_o - x_c)_{\mu} (x_o - x_c)^{\mu} = 0.
\eeq
Thereby $x_o^{\mu} \in \mathbb{R}^{3+1}$ denotes the observation point where the fields shall be calculated. Note, that on the left hand side of \eqref{eqn: constraint} only spatial components of the respective four vectors are used. \\
Plugging in \eqref{eqn: linInt} in \eqref{eqn: constraint} yields

\begin{multline}
\label{eqn: quadEq}
\lambda^2 (x_{j+1} - x_j)_{\mu}(x_{j+1} - x_j)^{\mu} + \lambda~2(x_{j+1} - x_j)_{\mu}(x_j - x_o)^{\mu} + (x_j)_{\mu}(x_j)^{\mu} \\ + (x_o)_{\mu}(x_o)^{\mu} - 2(x_j)_{\mu}(x_o)^{\mu}  = 0.
\end{multline}
We define
\beq
\bal
a &\coloneqq (x_{j+1} - x_j)_{\mu}(x_{j+1} - x_j)^{\mu}\\
b &\coloneqq 2(x_{j+1} - x_j)_{\mu}(x_j - x_o)^{\mu} \\
c &\coloneqq (x_j)_{\mu}(x_j)^{\mu} + (x_o)_{\mu}(x_o)^{\mu} - 2(x_j)_{\mu}(x_o)^{\mu}. \nn
\eal
\eeq
In general the quadratic equation \eqref{eqn: quadEq} in $\lambda$ has two solutions
\beq
\lambda_{1/2} = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}. \nn
\eeq
One solution denotes the intersection point with the backward lightcone, the other one with the forward lightcone. Since  $\lambda \in [0,1]$ we are only interested in the larger one. 
\beq
\lambda_{1/2} = \frac{-b + \sqrt{b^2 - 4ac}}{2a}. \nn
\eeq
Plugging in $\lambda$ in \eqref{eqn: linInt} gives the desired intersection point.

%======================== trilinear interpolation of fields ========================
\section{Trilinear Interpolation of Fields}
\label{sec: trilinear Interpolation}
Another interpolation method we are using is the trilinear interpolation to calculate the field values at the particle position more accurately. As is explained in more detail later (see Chapter \ref{cha: HybridFieldApproach}), field values will either be stored on grid points or calculated analytically. However, if we want to consider interactions between multiple particles correctly, we need the field values at the particle position which does usually not coincide with the grid point where the field values are stored. Matters were complicated further by the fact that our grid will be staggered, due to numerical stability issues and is explained in more detail in Section \ref{sec: Yee-Scheme}.\\
Let's assume we have a cube with the points A, B, C, ..., H, as is illustrated in the following Figure \ref{fig: trilinearInterpolation}
\begin{figure}[H]
	\centering
		\includegraphics[width=0.40\textwidth]{Pictures/trilinearInterpolation.pdf} 
	\caption[Cube with its eight corner points A, B, C, ..., H and interpolation point $P_f$.]{Cube with its eight corner points A, B, C, ..., H and interpolation point \textcolor{red}{$P_f$}. The points \textcolor{blue}{$P_1$},  \textcolor{blue}{$P_2$},  \textcolor{blue}{$P_3$} and \textcolor{blue}{$P_4$} are the result of an interpolation along x direction of the lines $\overline{AE}$, $\overline{CG}$, $\overline{BF}$ and $\overline{DH}$.  \textcolor{green}{$P_u$} and \textcolor{green}{$P_o$} are obtained by interpolating along y - axis of the lines $\overline{P_1P_2}$ and $\overline{P_3P_4}$. Finally, \textcolor{red}{$P_f$} can be obtained by interpolating along z direction of the line $\overline{P_uP_o}$.}
	\label{fig: trilinearInterpolation}
\end{figure}
\noindent
Those eight points are part of the grid and contain the field values for both $\vec{E}$ and $\vec{H}$. To get the correct field values at the particle position \textcolor{red}{$P_f$} we need to interpolate in 3D. The trilinear interpolation simply consists out of seven linear interpolations. We first interpolate the $x$ - value along $\overline{AE}$, $\overline{CG}$, $\overline{BF}$ and $\overline{DH}$ to get the points \textcolor{blue}{$P_1$},  \textcolor{blue}{$P_2$},  \textcolor{blue}{$P_3$} and  \textcolor{blue}{$P_4$}. Thereto let $x_p \in \mathbb{R}$ be the particle's $x$ position and $x_0 \in \mathbb{R}$ and $x_1 \in \mathbb{R}$ be the corresponding $x$ - values at A and E respectively. Same holds for the aforementioned tuples as well. Then we can write
\beq
\bal
u & \coloneqq \frac{x_p - x_0}{x_1 - x_0} \\
\Longrightarrow  \textcolor{blue}{P_1} &= A + u (E - A) \\
\Longrightarrow \textcolor{blue}{P_2} &= C + u (G - C) \\
\Longrightarrow \textcolor{blue}{P_3} &= B + u (F - B) \\
\Longrightarrow \textcolor{blue}{P_4} &= D + u (H - D).
\eal
\eeq
In the next step, we interpolate along the $y$ - axis. Analogously we define $y_p$, $y_0$ and $y_1$. We conclude
\beq
\bal
v &\coloneqq \frac{y_p - y_0}{y_1 - y_0} \\
\Longrightarrow  \textcolor{green}{P_u} &= \textcolor{blue}{P_1} + v (\textcolor{blue}{P_2} - \textcolor{blue}{P_1}) \\
\Longrightarrow  \textcolor{green}{P_o} &= \textcolor{blue}{P_3} + v (\textcolor{blue}{P_4} - \textcolor{blue}{P_3}).\\
\eal
\eeq
And finally with $z_p$, $z_0$ and $z_1$ we get
\beq
\bal
w &\coloneqq \frac{z_p - z_0}{z_1 - z_0} \\
\Longrightarrow  \textcolor{red}{P_f} &= \textcolor{green}{P_u} + v (\textcolor{green}{P_o} - \textcolor{blue}{P_u}).
\eal
\eeq
%======================== Hybrid Field Approach ========================
%===========================================================
\chapter{Hybrid Field Approach}
\label{cha: HybridFieldApproach}
In this section we introduce the concept of hybrid fields. Christian Herzing developed this concept in his dissertation \cite{Herzing} and showed how this approach reduces the numerical complexity from $N^2$ to $N$. 
Usually the numerical complexity of multi particle simulation is $N^2$, due to the interaction between each particle. In our case we need $N$ push operations for the particles. One push for each particle. In order to do that, however,  equation \eqref{eqn: Lorentz-Newton} needs to be solved and therefore all Liénard-Wiechert fields from the other $N-1$ particles are needed. This results in $N(N-1)$ calculations for each time step. If we want to calculate the Liénard-Wiechert fields, we also need to store all positions from all particles, as explained in Section \ref{sec: Interpolation of Trajectories}. For a few particles such simulations are effortlessly feasible. But with increasing particle numbers such simulations may not just require more and more memory capacity but also become so time consuming that at some point we simply can not do them any longer. That's where the hybrid field model comes in. Instead of calculating the Liénard-Wiechert fields at every time step for all particles at all grid points, the fields are stored onto the grid and propagated through the grid using Maxwell equations. How that works in detail is explained in the following sections. 

%%======================== Maxwell Equations ========================
%\section{Maxwell-Equations}
% MISSING: Which one to use ? For Maxwell Pusher  the vacuum equations are suffice. For UPML we need the ones in anisotropic media
%The Maxwell equations are the foundation of the classical electromagnetism and describe how the electric field $\vec{E} \in \mathbb{R}^3$ and the magnetic field $\vec{H} \in \mathbb{R}^3$ are generated by charges and currents respectively and how they evolve over time in space in presence of one another. In homogenous and isotropic media the Maxwell Equations read
%\beq
%\label{eqn: maxwellEq}
%\bal
%\epsilon_0\epsilon_r \vec{\nabla} \vec{E} &= \rho \\
%\mu_0\mu_r \vec{\nabla} \vec{B} &= 0\\
%\vec{\nabla} \times \vec{E} &= - \mu_0\mu_r \frac{\del \vec{B}}{\del t}\\
%\vec{\nabla} \times \vec{H} &=  \epsilon_0\epsilon_r \frac{\del \vec{E}}{\del t} + \sigma \vec{E},
%\eal
%\eeq
%where $\epsilon_0 $ and $\epsilon_r$ are the vacuum and the relative electric permeability respectively. Same holds for $\mu_0$ and $\mu_r $ for magnetic materials.
%$\rho$ denotes the current density of the electric source and $\sigma$ the electric conductivity. \\
%To solve the Maxwell equations numerically we need to discretize them first. The most robust and reliable way of doing this is with the \textit{Yee-Algorithm}. 

%======================== Yee Scheme ========================
\section{FDTD}
\label{sec: Yee-Scheme}
In this section we talk about how to solve the Maxwell Equations \eqref{eqn: maxwellEq} and how to propagate the fields on a numerical grid. We thereby focus on the Maxwell Equations in vacuum, i.e. $\rho = \vec{j} = 0$. As can be seen in the Liénard-Wiechert formula \eqref{eqn: Liénard-Wiechert} there is a singularity for the field values at the particle position itself. Thus, we just want to propagate fields far away from the source, which is explained in more detail later.\\
\newline 
To push the fields on the grid, i.e solving for the fields at the next time step, we use the Yee - Scheme introduced by \textit{Kane Yee} in 1966 \cite{Yee66} or equivalently \textit{Finite Difference Time Domain Method} to discretize the Maxwell Equations. Each point on the discretized grid is represented as a tuple $(i,j,k)$. One index for each dimension $(x,y,z)$. The distance between the grid points are $(\Delta x, \Delta y, \Delta z)$ respectively. $h$ denotes the time discretization as before. In order to have finite central differences rather than plain finite differences, the evaluation of $\vec{E}$ and $\vec{H}$ components are shifted in time about $\frac{h}{2}$ against each other. To have the same benefits for the rotation, the $\vec{E}$ and $\vec{H}$ components are shifted in space as well, as it's illustrated in Figure \ref{fig: YeeBox}.
\begin{figure}[H]
	\centering
		\includegraphics[width=0.70\textwidth]{Pictures/YeeBox.png} 
	\caption[Yee-Box]{An illustration of a so called Yee-Box which is used to solve the curl Maxwell Equations. Shown are the positions of the electric and magnetic field vector components about a cubic unit cell of the Yee space lattice.The Yee algorithm centers its E and H components in three- dimensional space so that every E component is surrounded by four circulating H components, and every H component is surrounded by four circulating E components \cite{Taflove}.}
	\label{fig: YeeBox}
\end{figure}
The discrete Maxwell equations then read
%\vec{E}^{n+\frac{1}{2}}_{(i,j,k)}
\beq
\label{eqn: discreteMaxwellEq}
\bal
\frac{\vec{E}\Bigr|^{n+\frac{1}{2}}_{(i,j,k)} - \vec{E}\Bigr|^{n-\frac{1}{2}}_{(i,j,k)}}{h} = \vec{\nabla}^{-} \times \vec{H}\Bigr|^{n}_{(i,j,k)},\\
\frac{\vec{H}\Bigr|^{n+1}_{(i,j,k)} - \vec{H}\Bigr|^{n}_{(i,j,k)}}{h} = \vec{\nabla}^{+} \times \vec{E}\Bigr|^{n+\frac{1}{2}}_{(i,j,k)}.
\eal
\eeq
The operators $\vec{\nabla}^{-}$ and $\vec{\nabla}^{+}$ act on a discretized vector field $F\Bigr|_{(i,j,k)}:\mathbb{R}^3 \to \mathbb{R}$ as follows
\beq
%F_{(i + 1,j,k)} - F_{(i,j,k)}{\Delta x}
\vec{\nabla}^{-} F\Bigr|_{(i,j,k)} \coloneqq \left( \frac{F\Bigr|_{(i,j,k)} - F\Bigr|_{(i-1,j,k)}}{\Delta x}, \frac{F\Bigr|_{(i,j,k)} - F\Bigr|_{(i,j-1,k)}}{\Delta y}, \frac{F\Bigr|_{(i,j,k1)} - F\Bigr|_{(i,j,k-1)}}{\Delta z}\right)^{T},\\
\vec{\nabla}^{+} F\Bigr|_{(i,j,k)} \coloneqq \left( \frac{F\Bigr|_{(i + 1,j,k)} - F\Bigr|_{(i,j,k)}}{\Delta x}, \frac{F\Bigr|_{(i,j + 1,k)} - F\Bigr|_{(i,j,k)}}{\Delta y}, \frac{F\Bigr|_{(i,j,k+1)} - F\Bigr|_{(i,j,k)}}{\Delta z}\right)^{T},
\eeq
where $T$ denotes the transpose as usual. The spatial positions where $\vec{E}$ and $\vec{H}$ components will be calculated are given by
\beq
\bal
\vec{E}\Bigr|_{(i,j,k)} &= 
\begin{pmatrix}
E_{x}\left[\left(i+\frac{1}{2}\right)\Delta x, j\Delta y,  k\Delta z\right]\\[0.5em]
E_{y}\left[i \Delta x, \left(j+\frac{1}{2}\right)\Delta y,  k\Delta z\right]\\[0.5em]
E_{z}\left[i\Delta x, j\Delta y,  \left(k+\frac{1}{2}\right)\Delta z\right]
\end{pmatrix}, \\
\vec{H}\Bigr|_{(i,j,k)} &= 
\begin{pmatrix}
H_{x}\left[i\Delta x, \left(j+\frac{1}{2}\right)\Delta y, \left(k+\frac{1}{2}\right)\Delta z\right]\\[0.5em]
H_{y}\left[\left(i+\frac{1}{2}\right) \Delta x, j\Delta y,  \left(k+\frac{1}{2}\right)\Delta z\right]\\[0.5em]
H_{z}\left[\left(i+\frac{1}{2}\right)\Delta x, \left(j+\frac{1}{2}\right)\Delta y, \Delta z\right]
\end{pmatrix}.
\eal
\eeq
%======================== Dispersion Relation ========================
\section{Numeric Dispersion Relation}
\label{sec: DispersionRelation}
By discretizing the numerical grid, the dispersion relation of light also changes. To study this effect we need to solve the discretized Maxwell Equations \eqref{eqn: discreteMaxwellEq}. Without loss of generality we choose the Ansatz of a TMz-mode, i.e. $H_z = 0$ and $E_z \neq 0$:
\beq
\bal
\label{eqn: TMz-mode}
E_z\Bigr|_{(i,j,k)}^{n} &= E_{z_0} \exp\left\{\hat{i}\left(\tilde{k}_x i\Delta x + \tilde{k}_y i\Delta y - \omega nh\right)\right\}\\
H_x\Bigr|_{(i,j,k)}^{n} &= H_{x_0} \exp\left\{\hat{i}\left(\tilde{k}_x i\Delta x + \tilde{k}_y i\Delta y - \omega nh\right)\right\}\\
H_y\Bigr|_{(i,j,k)}^{n} &= H_{y_0} \exp\left\{\hat{i}\left(\tilde{k}_x i\Delta x + \tilde{k}_y i\Delta y - \omega nh\right)\right\},
\eal
\eeq
where $\hat{i}$ denotes the imaginary unit and $\tilde{k}_x$, $\tilde{k}_y$ the x- and y-components of the wave vector. Using TMz-mode, equation \eqref{eqn: discreteMaxwellEq} also simplifies to
\beq
\bal
\label{eqn: simplifiedMaxwellEq}
\frac{E_z\Bigr|^{n+\frac{1}{2}}_{(i,j,k)} - E_z\Bigr|^{n-\frac{1}{2}}_{(i,j,k)}}{h} &= \left( \frac{H_y\Bigr|^{n}_{(i,j,k)} - H_y\Bigr|^{n}_{(i-1,j,k)}}{\Delta x} - \frac{H_x\Bigr|^{n}_{(i,j,k)} - H_x\Bigr|^{n}_{(i,j-1,k)}}{\Delta y}\right)\\
\frac{H_x\Bigr|^{n+1}_{(i,j,k)} - H_x\Bigr|^{n}_{(i,j,k)}}{h} &= - \left(\frac{E_z\Bigr|^{n+\frac{1}{2}}_{(i,j+1,k)} - E_z\Bigr|^{n+\frac{1}{2}}_{(i,j,k)}}{\Delta y}\right)\\
\frac{H_y\Bigr|^{n+1}_{(i,j,k)} - H_y\Bigr|^{n}_{(i,j,k)}}{h} &= \left(\frac{E_z\Bigr|^{n+\frac{1}{2}}_{(i+1,j,k)} - E_z\Bigr|^{n+\frac{1}{2}}_{(i,j,k)}}{\Delta x}\right).
\eal
\eeq
Upon substituting \eqref{eqn: TMz-mode} in \eqref{eqn: simplifiedMaxwellEq} and after some manipulation we find
\beq
E_{z_0}\sin\left(\frac{\omega h}{2}\right) &=& h\left[\frac{H_{x_0}}{\Delta y}\sin\left(\frac{\tilde{k}_y \Delta y}{2}\right) - \frac{H_{y_0}}{\Delta x}\sin\left(\frac{\tilde{k}_x \Delta x}{2}\right)\right]\\[0.5em]
\label{eqn: Hx0}
H_{x_0} &=& \frac{h E_{z_0}}{\Delta y} \frac{\sin\left(\frac{\tilde{k}_y \Delta y}{2}\right)}{\sin\left(\frac{\omega h}{2}\right)}\\[0.5em]
\label{eqn: Hy0}
H_{y_0} &=& \frac{h E_{z_0}}{\Delta x} \frac{\sin\left(\frac{\tilde{k}_x \Delta x}{2}\right)}{\sin\left(\frac{\omega h}{2}\right)}.
\eeq
Plugging in \eqref{eqn: Hx0} and \eqref{eqn: Hy0} in \eqref{eqn: simplifiedMaxwellEq} we obtain the numerical dispersion relation
\beq
\bal
\label{eqn: dispersionRelation2D}
\left[\frac{1}{h}\sin\left(\frac{\omega h}{2}\right)\right]^2 = \left[\frac{1}{\Delta x}\sin\left(\frac{\tilde{k}_x \Delta x}{2}\right)\right]^2  + \left[\frac{1}{\Delta y}\sin\left(\frac{\tilde{k}_y \Delta y}{2}\right)\right]^2 \\
\eal
\eeq
For the one dimensional case equation \eqref{eqn: dispersionRelation2D} reduces to 
\beq
\label{eqn: dispersionRelation1D}
\omega h = 2\arcsin\left(\frac{\Delta t}{\Delta x} \sin\left(\frac{\tilde{k}_x \Delta x}{2}\right)\right),
\eeq
which is still more complicated than the analytic dispersion relation
\beq
\omega = k.
\eeq
In Figure \ref{fig: dispersionRelation} both, the analytical and the numerical dispersion relation are plotted. Equation \eqref{eqn: dispersionRelation1D} has a maximum at 
\beq
\bal
\tilde{k}_x^{max} &= \frac{\pi}{\Delta x}\\
\Longleftrightarrow\lambda_x^{max} &= 2 \Delta x.
\eal
\eeq
$\tilde{k}_x^{max}$ is the largest possible wavevector - also called \textit{Nyquist Limit} for a numerical grid with resolution $\Delta x$, or $\Delta y$, $\Delta z$ respectively. At this wavevector, the group velocity 
\beq
v_g = \frac{\del \tilde{k}_x}{\del \omega}\Bigr|_{\tilde{k} = \tilde{k}^{max}} = 0
\eeq
vanishes, instead of propagating with speed of light. That means, that the Yee-Scheme is only valid for wavelengths $\lambda \ll \lambda^{max}$.
\begin{figure}[H]
	\centering
		\includegraphics[width=0.60\textwidth]{Pictures/dispersionRelation.png} 
	\caption[Comparison of numerical and analytical dispersion relation of discretized Maxwell Equations with Yee Scheme]{Comparison of numerical and analytical dispersion relation of discretized Maxwell Equations with Yee Scheme. We used $c \equiv 1$ and $\frac{\Delta t}{\Delta x} \equiv \frac{1}{2}$. At $\tilde{k}_x^{max} = \frac{\pi}{\Delta x}$ the group velocity vanishes instead of propagating with speed of light. Therefore, only waves with $\lambda \ll \lambda^{max}$ can be resolved properly on the grid.}
	\label{fig: dispersionRelation}
\end{figure}
\noindent

After having discussed the fundamentals, we now want to dive into practice. In Section \ref{sec: Yee-Scheme} we learned how to store and propagate the fields on a numerical grid. In Section \ref{sec: lw-potentials} we derived an analytical expression, of how to calculate the fields of a moving charged particle. We also observed that there is a singularity in \eqref{eqn: Liénard-Wiechert} at the particle position itself. That means, that the fields will vary strongly in  a vicinity of the particle and can not be resolved correctly on the grid, as discussed in Section \ref{sec: DispersionRelation}. Hence, it seems plausible to separate the simulation area into appropriate Near - and far field areas. Within the near field area of a particle, its fields will \textbf{not} be stored on the grid. We then do not need to worry about the singularity. Only far fields from other particles, propagated into the near field area will be further propagated and stored on the grid. Possible interactions with other particles within the near field area will be caluclated analytically from \eqref{eqn: Liénard-Wiechert}. \\
far fields will be stored on the grid and propagated with the Yee-Scheme \eqref{eqn: discreteMaxwellEq}.
%======================== Near and Far- Fields ========================
\section{Near-and Far Fields}
Before we can separate the simulation area into Near - and far fields, we need to initialize a grid. We divide the grid in \texttt{numberBoxesInX}, \texttt{numberBoxesInY} and \texttt{numberBoxesInZ} boxes, each of which has \texttt{numberOfGridPointsForBoxInX}, \texttt{numberOfGridPointsForBoxInY} and \texttt{numberOfGridPointsForBoxInZ} length, which leaves us with a total 
\begin{lstlisting}
numberOfGridPointsInX = numberOfGridPointsForBoxInX * numberOfBoxesInX;
numberOfGridPointsInY = numberOfGridPointsForBoxInY * numberOfBoxesInY;
numberOfGridPointsInZ = numberOfGridPointsForBoxInZ * numberOfBoxesInZ;
\end{lstlisting}
Upon defining the resolution \texttt{dx}, \texttt{dy}, \texttt{dz} the size of the simulation area is then given by 
\begin{lstlisting}
lengthOfSimulationBoxInX = numberOfGridPointsInX * dx;
lengthOfSimulationBoxInY = numberOfGridPointsInY * dy;
lengthOfSimulationBoxInZ = numberOfGridPointsInZ * dz;
\end{lstlisting}
The near field is then defined as the $3 \cdot 3 \cdot 3 = 27$ boxes with the box, containing the particle, in the center. In Figure \ref{fig: near fields} the near fields of one and two particles are shown. The near fields can of course overlap. The near field box at $(18,18)$ belongs to both particles.
\begin{figure}[t]
\subfigure[]{\includegraphics[width=0.49\textwidth]{Pictures/nearFieldOneParticle.png}}\hfill
\subfigure[]{\includegraphics[width=0.49\textwidth]{Pictures/nearFieldTwoParticles.png}}
\caption[near fields of one and two particles]{near fields of one (a) and two (b) particles. The box at $(18,18)$ belongs to the near field of both particles, marked with $e^{-}$. Notice the staggered red grid in the background. In this example we used 8 boxes, with 20 grid points each, and a resolution of $dx = dy = dz = 0.2$. The plotted plane was chosen accordingly to the z - coordinate of the particle.}	
\label{fig: near fields}
\end{figure}
\noindent

%======================== Field Push ========================
\newpage
\section{Field Push}
We now want to explain, how a field push actually works. Since we only propagate fields in the far field area as explained in Section \ref{sec: Yee-Scheme} special care needs to be taken at the boundaries between far field and near field. To explain this, consider the following plane of a grid illustrated in Figure \ref{fig: nearFieldFarFieldBorder}.
\begin{figure}[t]
	\centering
		\includegraphics[width=0.50\textwidth]{Pictures/createdPictures/grid.pdf} 
	\caption[One plane of a grid showing the near field and far field of a particle. The near field does not contain any field values of the particle]{One plane of a grid showing the \textcolor{red}{near field} and far field of a particle. The \textcolor{red}{near field} does not contain any field values of the particle. $k$ denotes the plane at an height $z$ and can be chosen arbitrarily here.}
	\label{fig: nearFieldFarFieldBorder}
\end{figure}
\noindent
The \textcolor{red}{red} dots are considered to be the near field area of a particle. The black dots are therefore the far field area. The grid points within the near field does not contain any field values. We only store and propagate fields on the grid points in the far field. If we now want to push the value for $H_z$ at $(2,4,k)$ (recall that each grid point contains the field values for either $H_x$, $H_y$, $H_z$ or $E_x$, $E_y$, $E_z$ due to the staggered grid, explained in Section \ref{sec: Yee-Scheme}), where $k \in (1, 2, 3, \ldots , \text{numberOfGridPointsInZ} - 1 )$, we need to solve 
\beq
\frac{\del H_z}{\del t} = - \left( \frac{\del E_y}{\del x} - \frac{\del E_x}{\del y} \right).
\eeq
Using the discretized Maxwell Equations \eqref{eqn: discreteMaxwellEq} we get
\beq
\vec{H}\Bigr|^{n+1}_{z (2,4,k)} = \vec{H}\Bigr|^{n}_{z (2,4,k)} - h \left(\frac{\textcolor{red}{E\Bigr|^{n+\frac{1}{2}}_{y (3,4,k)}} - E\Bigr|^{n+\frac{1}{2}}_{y (2,4,k)}}{\Delta x} - \frac{E\Bigr|^{n+\frac{1}{2}}_{x (2,5,k)} - E\Bigr|^{n+\frac{1}{2}}_{y (2,4,k)}}{\Delta y}\right).
\eeq
\noindent
$\vec{H}\Bigr|^{n+1}_{z (2,4,k)}$ is stored on a far field grid point. Its calculation, however, requires a field value $\textcolor{red}{E\Bigr|^{n+\frac{1}{2}}_{y (3,4,k)}}$, which is stored on a near field grid point and therefore contains no field values from the particle (it can, however, contain field values from other particles propagated from the outside into the near field area). Hence, we need to analytically calculate the Liénard-Wiechert field \eqref{eqn: Liénard-Wiechert} of the particle at $(3,4,k)$ $\textcolor{blue}{E\Bigr|^{n+\frac{1}{2}}_{yp (3,4,k)}}$ and add it to the field value already stored at this grid point. Finally, the correct calculation is
\begin{multline}
\vec{H}\Bigr|^{n+1}_{z (2,4,k)} = \vec{H}\Bigr|^{n}_{z (2,4,k)} \\ - h \left(\frac{\left(\textcolor{red}{E\Bigr|^{n+\frac{1}{2}}_{y (3,4,k)}} + \textcolor{blue}{E\Bigr|^{n+\frac{1}{2}}_{yp (3,4,k)}}\right) - E\Bigr|^{n+\frac{1}{2}}_{y (2,4,k)}}{\Delta x} - \frac{E\Bigr|^{n+\frac{1}{2}}_{x (2,5,k)} - E\Bigr|^{n+\frac{1}{2}}_{y (2,4,k)}}{\Delta y}\right).
\end{multline}
\noindent
On the contrary, if we want to push the value for $H_z$ at $\textcolor{red}{(6,4,k)}$ we need to analytically calculate the Liénard-Wiechert field \eqref{eqn: Liénard-Wiechert} of the particle at $(7,4,k)$ $\textcolor{blue}{E\Bigr|^{n+\frac{1}{2}}_{yp (7,4,k)}}$ and subtract it from the field value already stored at this grid point. $(7,4,k)$ already contains the field contribution of the particle, since it is a far field grid point. And because $\textcolor{red}{(6,4,k)}$ is a near field grid point we only want to take contributions from other particles into account, which are about to propagate into our near field area. After subtracting the particles own contributions, the correct push can be calculated via
\begin{multline}
\textcolor{red}{\vec{H}\Bigr|^{n+1}_{z (6,4,k)}} = \textcolor{red}{\vec{H}\Bigr|^{n}_{z (6,4,k)}} \\ - h \left(\frac{\left(E\Bigr|^{n+\frac{1}{2}}_{y (7,4,k)} - \textcolor{blue}{E\Bigr|^{n+\frac{1}{2}}_{yp (7,4,k)}}\right) - \textcolor{red}{E\Bigr|^{n+\frac{1}{2}}_{y (6,4,k)}}}{\Delta x} - \frac{\textcolor{red}{E\Bigr|^{n+\frac{1}{2}}_{x (6,5,k)}} - \textcolor{red}{E\Bigr|^{n+\frac{1}{2}}_{y (6,4,k)}}}{\Delta y}\right).
\end{multline}
\noindent
This and more examples as well as a more detailed explanation can be found in \cite{Herzing}. All points along the border between near - and far field need to be adjusted accordingly. \\
\newline
We now want to explain how this works out in code. Figure \ref{fig: CodeRoutineBoxes} shows three boxes, two of which are near field boxes and one is a far field box. For reasons of clarity we only show the grid points along the edges.
\begin{figure}[H]
	\centering
		\includegraphics[width=0.70\textwidth]{Pictures/createdPictures/boxes.pdf} 
	\caption[Section of a grid with three boxes, two of which are near field boxes (NF) and one being a far field box (FF)]{Section of a grid with three boxes, two of which are near field boxes (NF) and one being a far field box (FF). The colored planes represent those grid points, where adjustments are necessary, as explained above. One $\vec{E}$ - Field push consists of four steps, or equivalently four subroutines in code: 1. \texttt{pushEFieldInsideBoxes}, 2. \texttt{setHFieldOnBorders}, 3. \texttt{adjustHFields}, 4 \texttt{pushEFieldAtBorders}. For reasons of clarity we left out the grid points within the boxes. }
	\label{fig: CodeRoutineBoxes}
\end{figure}
\noindent
One complete field push consists out of four steps. Even though the field pushes for $\vec{H}$ and $\vec{E}$ are conceptionally identical, they differ in the grid points they are accessing to calculate the rotations $\vec{\nabla}^{+}$ and $\vec{\nabla}^{-}$ in \eqref{eqn: discreteMaxwellEq}. The steps (subroutines) for one $\vec{E}$ - Field push are
\begin{enumerate}
\item \texttt{pushEFieldInsideBoxes()}
\item \texttt{setHFieldOnBorders()}
\item \texttt{adjustHField()}
\item \texttt{pushEFieldOnBorders()}
\end{enumerate}
Since this is the core of the simulation, these steps will be explained in more detail below.
\subsection{pushEFieldInsideBoxes()}
In this routine we simply calculate the discretized Maxwell Equations \eqref{eqn: discreteMaxwellEq}. We loop through the entire grid and store the necessary field values
but leave out those grid points which are on the left plane (yz - plane) of each box. In Figure \ref{fig: CodeRoutineBoxes} marked with \textcolor{red}{red}.
\newline 
Now all $\vec{E}$ values in all boxes are pushed except those on the \textcolor{red}{red} plane. To push those we need to access the field values on the \textcolor{blue}{blue} and \textcolor{green}{green} plane, which are in the far field and therefore need to be adjusted. 

\subsection{setHFieldOnBorders()}
In order to push $\vec{E}$ we need values of $\vec{H}$. Therefore, this methods loops through all boxes and stores all values of $\vec{H}$ in the plane \textcolor{blue}{left}, in front and \textcolor{green}{below} of the current box (the plane in front is not shown for reasons of clarity). As can be seen from the Yee Scheme only Hy and Hz are needed from the left plane. Hz and Hx are needed from the plane in front and Hy and Hx are needed from the plane below. If the current box is a box where to the left does not exist then the respective values for H are set to zero.

\subsection{adjustHField()}
This routine consists of three subroutines \texttt{adjustHyz\_im1()}, \texttt{adjustHxz\_jm1()} and \\
 \texttt{adjustHxy\_km1()}. The first adjusts Hy and Hz on plane to the \textcolor{blue}{left}, the second adjusts Hx and Hz on the plane in front (not shown) and the latter adjusts Hx and Hy on the plane \textcolor{green}{below}. All of those three subroutines do conceptionally the same. They loop through all boxes and check whether the current box is part of the near field of the particle and the box to the left is not. This is the situation shown in Figure \ref{fig: CodeRoutineBoxes}. Then the respective Liénard-Wiechert fields get calculated on the \textcolor{blue}{blue} plane and subtracted from the values stored by \texttt{setHFieldOnBorders()}. Notice that the \textcolor{red}{red} plane is part of a near field box and the \textcolor{blue}{blue} plane is part of a far field box. Hence, we need to subtract the field contributions of the particle on the \textcolor{blue}{blue} plane.\\
On the contrary, if we have the case that the current box is a far field box and the box to left is a near field box, then the \textcolor{red}{red} plane is part of a far field box and the \textcolor{blue}{blue} plane is part of a near field box. Hence, we calculate the Liénard-Wiechert fields on the \textcolor{blue}{blue} plane and add them to the respective values stored by \texttt{setHFieldOnBorders()}.

\subsection{pushEFieldOnBorders()}
This method finally pushes the $\vec{E}$ - Field with the adjusted values. It also loops through the entire grid, but only gets active if the current grid point lies on the \textcolor{red}{red} plane. If so, then it gets the values stored by \texttt{setHFieldOnBorders()} and adjusted by \texttt{adjustHField()} and uses them to calculate the discretized Maxwell Equation \eqref{eqn: discreteMaxwellEq}.\\

The routines for pushing the $\vec{H}$ - Field are analogously:
\begin{enumerate}
\item \texttt{pushHFieldInsideBoxes()}
\item \texttt{setEFieldOnBorders()}
\item \texttt{adjustEField()}
\item \texttt{pushHFieldOnBorders()}
\end{enumerate}
while using the planes to the right, behind and above. \\
\newline
As an example we simulate an electron with $\gamma = 1.1$ in a constant external $B_z$ field. Figure \ref{fig: gyration electron} shows the result.
\begin{figure}[H]
\subfigure[t = 7]{\includegraphics[width=0.33\textwidth]{Pictures/gyration_7.png}}\hfill
\subfigure[t = 9]{\includegraphics[width=0.33\textwidth]{Pictures/gyration_9.png}}\hfill
\subfigure[t = 11]{\includegraphics[width=0.33\textwidth]{Pictures/gyration_11.png}}
\caption[Simulation of an electron with $\gamma = 1.1$ in a constant $B_z = 1$ field]{Simulation of an electron with $\gamma = 1.1$ in a constant $B_z = 1$ field. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3)  = 9.40 \cdot 10^{-24}\si{\second}$.}	
\label{fig: gyration electron}
\end{figure}
\noindent
The electron moves in a circular fashion in the $xy$ - plane. The red line in the center of the near field area shows the particles trajectory. The initial conditions are chosen such that the particle does not leave its initial box. That means that the near field does not change during runtime. The Liénard-Wiechert fields are only calculated at the border between near - and far field and only if the retardation constraint $t_{ret} > 0$ is met. \\
As we already mentioned before, Figure \ref{fig: gyration two electrons} finally shows the expected behavior of two particle's far fields propagating into each other's near field regions. 
\begin{figure}[H]
	\centering
		\includegraphics[width=0.50\textwidth]{Pictures/gyrationTwoParticles.png} 
	\caption[Gyration of two electrons with $\gamma = 1.1$ each.]{Gyration of two electrons with $\gamma = 1.1$ each.  This shows the expected behavior of two particle's far fields propagating into each other's near field regions. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$ and length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$.}
	\label{fig: gyration two electrons}
\end{figure}
\noindent
But what if the particle does leave its initial box ? 

%======================== Particle Push and near field update ========================
\section{Particle Push and Near Field Update}
In order to push the particle properly not just the external fields but also the field contributions from other particles propagated into the near field region need to be taken into account. To get an even better result we use trilinear interpolation (see Section \ref{sec: trilinear Interpolation}) to interpolate the field value at the particle position from the surrounding eight grid points. If, however, another particle2 enters the near field region of the observed particle1 equation \eqref{eqn: Liénard-Wiechert} is used to calculate the field emitted by particle2 at the position of particle1 analytically. \\
\newline
If a particle changes its box during one push from time $t$ to $t + \dm t$ the particles near field changes as illustrated in Figure \ref{fig: nearFieldUpdate}
\begin{figure}[H]
	\centering
		\includegraphics[width=0.40\textwidth]{Pictures/nearFieldUpdate.png} 
	\caption[Particle push from time $t$ to $t + \dm t$. Since the particle changes its box the near field region also changes]{\textcolor{blue}{Particle} push from time $t$ to $t + \dm t$. Since the particle changes its box the near field region also changes. The boxes marked with \includegraphics[height=12pt]{Pictures/nearFieldOldBoxes.png} do no longer belong to the near field, whereas the boxes marked with \includegraphics[height=12pt]{Pictures/nearFieldNewBoxes.png} do now belong to the near field area. Boxes illustrated as \includegraphics[height=12pt]{Pictures/nearFieldBoth.png} remain as near field boxes. \cite{Herzing}}
	\label{fig: nearFieldUpdate}
\end{figure}
\noindent
There are three situations we need to take care of. First the boxes which do not longer belong to the near field area, marked with \includegraphics[height=12pt]{Pictures/nearFieldOldBoxes.png} in Figure \ref{fig: nearFieldUpdate}. Since those boxes were part of the near field they didn't contain any field contributions of the particle. But because they are no longer part of the near field region those field contributions need to be added. The routine \texttt{addLWFieldsInBox()} calculates the Liénard-Wiechert field \eqref{eqn: Liénard-Wiechert} of the particle at all grid points in the specified box and adds them to the respective grid point. Second, all boxes marked with \includegraphics[height=12pt]{Pictures/nearFieldNewBoxes.png} are now part of the near field region and therefore the Liénard-Wiechert field of the particle at all grid points in the specified box need to be subtracted. The routine \texttt{subLWFieldsInBox()} does exactly that. Lastly, there are boxes which remain as part of the near field area marked with \includegraphics[height=12pt]{Pictures/nearFieldBoth.png}. Nothing needs to be done here.\\
As an example we simulate an electron with $\gamma = 1.2$ in a crossed $\vec{E}$ and $\vec{B}$ field. The results are shown in Figure \ref{fig: electronCrossedField}
\begin{figure}[H]
\subfigure[t = 5]{\includegraphics[width=0.33\textwidth]{Pictures/crossedField_5.png}}\hfill
\subfigure[t = 7]{\includegraphics[width=0.33\textwidth]{Pictures/crossedField_7.png}}\hfill
\subfigure[t = 9]{\includegraphics[width=0.33\textwidth]{Pictures/crossedField_9.png}}
\caption[Simulation of an electron with $\gamma = 1.2$ in a crossed electromagnetic field with $B_z = 1$ and $E_y$ = 0,2]{Simulation of an electron with $\gamma = 1.2$ in a crossed electromagnetic field with $B_z = 1$ and $E_y$ = 0,2. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3)  = 9.40 \cdot 10^{-24}\si{\second}$}	
\label{fig: electronCrossedField}
\end{figure}
\noindent

%======================== Particle History ========================
\section{Particle History}
\label{sec: Particle History}
In order to calculate the Liénard-Wiechert Field according to \eqref{eqn: Liénard-Wiechert} at an observation point, i.e. a grid point, the intersection point of the particles trajectory with the backward lightcone of that observation point is needed. For a more detailed explanation see Section \ref{sec: Interpolation of Trajectories}. That means, that we first have to store all positions of the particle. Second we need to track them along the trajectory to check whether the backward lightcone was crossed or not. To store the entire trajectory of a few particles is not very memory consuming.  However, if we want to simulate $10^{10}$ or even $10^{20}$ particles we would need a huge amount of memory just to store the trajectories. Let's do a rough calculation:\\
One position contains of four Doubles. One for time, three for spacial components. A Double has 8 \si{\byte}. That makes a total of 32 \si{\byte} memory for one particle position. If we want to simulate for $t = 10$ with a resolution of $dx = dy = dz = 0.1$ using Yee-Scheme we will have $\frac{10}{0.5 \cdot 0.1} = 200$ steps. That gives us $200 \cdot 32~\si{\byte} = 6.4~\si{\kilo\byte}$. For $10^{10}$ particles this sums up to 64 \si{\tera\byte}. This is not feasible! Not to mention that there is a lot more memory necessary to store all the calculated fields on the grid.\\
\newline
The problem is that we can't simply delete the positions we already used to find an intersection point, because the intersection point depends on the particles velocity. The faster the particle gets, the longer the history needs to be. We can see why that is in the following picture \ref{fig: particleHistory}
\begin{figure}[H]
\subfigure[$v = 0$]{\includegraphics[width=0.33\textwidth]{Pictures/createdPictures/historyLengthStill.pdf}}\hfill
\subfigure[$v \approx 0.5 c$]{\includegraphics[width=0.33\textwidth]{Pictures/createdPictures/historyLengthHalfC.pdf}}\hfill
\subfigure[$v \approx c$]{\includegraphics[width=0.33\textwidth]{Pictures/createdPictures/historyLengthAlmostC.pdf}}
\caption[The faster the particle gets, the longer the history needs to be]{Observation point $x_o$ at time $ct$. The particle trajectory is shown in ocher. The intersection point is marked red. We can see that the faster the particle gets the longer the particle history needs to be in order to find the intersection point. At the speed of light there would be no intersection point, since the backward lightcone and the particle history would be parallel. }	
\label{fig: particleHistory}
\end{figure}
\noindent
We see an observation point $x_o$ and its backward lightcone in a Minkowsky Space. The ocher line illustrates the particles trajectory, crossing the backward lightcone at an intersection point, marked as red dot. With increasing velocity the trajectory tends more and more towards a $45^\circ$ angle. At $v = c$ the trajectory would be parallel to the backward lightcone and thus an intersection would be impossible. Therefore, we can conclude that a plausible criteria for finding the position after which all following positions could be neglected has to be velocity dependent. Due to the aforementioned arguments we can moreover conclude that the dependence would be proportional to $\frac{1}{1 - \beta}$. \\
But this is not good enough. Since the velocity can change during runtime, we need an a priori approach to reduce the memory consumption. As discussed in Section \ref{sec: Energy emission} we know that the intensity declines with a $\frac{1}{r^2}$ dependance.
This allows us to define a distance over which the emitted fields would be attenuate so much, that they could be neglected. Unfortunately we were not able to develop a concrete formulation of that idea, yet. So we have not implemented and tested it so far.   

%======================== Far field Setup Before Simulation ========================
\newpage
\section{Far Field Setup Before Simulation}
So far we can initialize a particle (or multiple particles) and let them move on the grid according to the Lorentz-Newton equation \eqref{eqn: Lorentz-Newton} without damping. If there are external fields or interaction forces between multiple particles they get accelerated and start to radiate Liénard-Wiechert fields. As soon as the retardation constraint is met ($t_{ret} > 0$) the fields will appear at the border between near - and far field region and get propagated via \eqref{eqn: discreteMaxwellEq}. This works fine, but unfortunately this initial setup is far from realistic. The particles were not created the second the simulation starts. We are not interested in simulating the creational process but the emitted fields due to interactions between particles which do already exist. Therefore, the particles will already have a long trajectory history and some kind of Liénard-Wiechert fields coming with them. So, the question is: How do we setup the fields on the grid before the simulation starts ? We use the following approach:\\
We use the Boris-Pusher (see Section \ref{sec: Boris-Method}) to push the particles from $t$ to $t + \dm t$, starting with the initial conditions, given prior to the simulation. This algorithm can also be used to push backwards in time, since it is symplectic and therefore time reversible. By selecting the simulation parameter $\texttt{t} = t_0 > 0$ the trajectory will be calculated backwards in time for $t_0$ time units. This can be achieved by reversing the external fields and the initial velocity vector of the particle. Once we got $t_0$ back in time, we reverse the external fields and the velocity vector again, set the particles proper time to zero and start pushing the particle from there. In order to store all new trajectory points in the history, it needs to be extended by $\frac{t_0}{\dm t}$ elements first. With this approach the simulation starts with the particle being at the specified initial conditions by the user, but the particle will already have a trajectory history, from which the initial Liénard-Wiechert fields can be calculated with \eqref{eqn: Liénard-Wiechert} in all far field boxes of the grid. This, however, is computationally quite expensive. We therefore developed a routine which serializes the initial conditions of the simulation in a file and only calculates the fields if they were not calculated and stored before. The flow chart in Figure \ref{fig: particleHistoryFlowChart} shows which functions get called when the user sets $t = t_0 > 0$.
In Figure \ref{fig: particleHistoryExamples} some examples of initial fields for different times are shown. Notice that in all cases the simulation starts with the particle being at the initial position \footnote{$\texttt{Particle->x[1]} = 11.1$\\ $\texttt{Particle->x[2]} = 15.5$} the user entered prior to the simulation. Only the distance over which the fields are initialized differ due to different particle history length.
\begin{figure}[H]
\subfigure[$\texttt{t} = 8$, $\texttt{tEnd} = 9$]{\includegraphics[width=0.33\textwidth]{Pictures/particleHistoryInitialFields8.png}}\hfill
\subfigure[$\texttt{t} = 10$, $\texttt{tEnd} = 11$]{\includegraphics[width=0.33\textwidth]{Pictures/particleHistoryInitialFields10.png}}\hfill
\subfigure[$\texttt{t} = 12$, $\texttt{tEnd} = 13$]{\includegraphics[width=0.33\textwidth]{Pictures/particleHistoryInitialFields12.png}}
\caption[Initial fields for different values of simulation parameter $\texttt{t}$]{Initial fields for different values of simulation parameter $\texttt{t}$. If $\texttt{t} > 0$ the history gets extended with a reverse Boris Push such that the initial conditions are still met at the beginning of the simulation. The Liénard-Wiechert fields are calculated from the extended particle history.\\ 
The electron has an energy of $\gamma = 1.2$. We used a constant $B_z = 1$ as external field. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$}	
\label{fig: particleHistoryExamples}
\end{figure}
\noindent

\begin{figure}[H]
	\centering
		\includegraphics[width=0.7\textwidth]{Pictures/createdPictures/particleHistoryFlowChart.pdf} 
	\caption[Flow Chart showing the relevant function calls when the user sets $t = t_0 > 0$]{Flow Chart showing the relevant function calls when the user sets $t = t_0 > 0$. If $t = t_0 = 0$ the simulation starts right away.}
	\label{fig: particleHistoryFlowChart}
\end{figure}
\noindent

%======================== Electron Scattering in an electromagnetic wave ========================
\section{Electron Scattering in an electromagnetic wave}
\label{sec: electron scattering}
Finally, to proof the framework's proper functionality, an electron scattering process with a laser pulse shall be simulated, which could be reproduced in the lab. Due to the normalization (see Appendix \ref{app: Normalization}) the scales need to be adapted in order to have realistic scales. For instance, the ratio of the normalized characteristic frequency $\omega$ to the laser frequency $\omega_L$ needs to be calculated first. We also need to find the ratio of the normalized electric field amplitude $E_0$ to the laser electric field amplitude $E_{0L}$ and also a proper time resolution. In the following we present a rough estimate of the aforementioned quantities.\\
\newline
In order to find $\frac{\omega_L}{\omega}$ we start with the laser amplitude $a_0$, which us usually of the order
\beq
a_0 = \frac{eE_{0L}}{m_e\omega_Lc} = 100.
\eeq
Typical laser wavelengths are of the order 
\beq
\bal
\lambda_L &= 10^{-6} \si{\meter} = 1 \si{\micro\meter} \\
\Longrightarrow \nu_L &= \frac{c}{\lambda_L} \approx 3 \cdot 10^{14} \si{\per\second} \\
\Longrightarrow \omega_L &= 2\pi\nu_L = 1.88 \cdot 10^{15}\si{\per\second}.
\eal
\eeq
Since
\beq
\omega = \frac{4\pi\epsilon_0m_ec^3}{q^2} = 1.06 \cdot 10^{23} \si{\per\second} 
\eeq
we find
\beq
\label{eqn: ratio omega}
\frac{\omega_L}{\omega} = 1.77 \cdot 10^{-8} \si{\per\second}. 
\eeq
Using the relationship between $\omega_L$ and $\omega$ we can find 
\beq
\bal
E_{0L} &\equiv \frac{a_0m_e\omega_Lc}{q} \\
&= 100 \frac{m_ec}{q} \cdot 1.77 \cdot 10^{-8}  \frac{4\pi\epsilon_0m_ec^3}{q^2} \\
& = 1.77 \cdot 10^{-6}  \frac{4\pi\epsilon_0m^2_ec^4}{q^3} \\
& = 1.77 \cdot 10^{-6} E_0.
\eal
\eeq
The same holds for $B_{0L}$. Finally, we need to determine the grid resolution $dx$ and therefore $dt$. In order to resolve the fields properly on the grid, the time resolution needs to be so small that 
\beq
\Delta t_L \omega_L \ll 1
\eeq
holds. Plugging in yields
\beq
\bal
\Delta t_L &\ll \frac{1}{\omega_L} \stackrel{\eqref{eqn: ratio omega}}{=} \frac{1}{1.77 \cdot 10^{-8} \omega} = 1.77 \cdot 10^{8} t.
\eal
\eeq
Since $dt = 0.5 dx$ (see Section \ref{sec: Yee-Scheme}) choosing $dx = 10^{7}$ is sufficiently small.\\
\newline
For the upcoming results the following settings were used
\begin{lstlisting}
Resolution->dx = pow(10,7);
Resolution->dy = pow(10,7);
Resolution->dz = pow(10,7);

Box->numberOfGridPointsInX = 32;
Box->numberOfGridPointsInY = 32;
Box->numberOfGridPointsInZ = 32;
    
Grid->numberOfBoxesInX = 22;
Grid->numberOfBoxesInY = 10;
Grid->numberOfBoxesInZ = 10;
    
int numberOfParticles = 1;
    
double dt = 0.5 * Resolution.dx;
double t = 400 * pow(10, 7);
double tEnd = 1100 * pow(10, 7);
    
Particle1->mass = pow(10, 10);
Particle1->charge = pow(10, 10);
    
Particle1->x[0] = 0;
Particle1->x[1] = 6.0 * pow(10, 9);
Particle1->x[2] = 1.6 * pow(10, 9);
Particle1->x[3] = 1.6 * pow(10, 9);
\end{lstlisting}
For the external laser pulse we modulated a cosine function with a sin squared function in x direction and a gaussian in y direction. Figure \ref{fig: external Pulse} shows the external pulse. 

\begin{figure}[H]
	\centering
		\includegraphics[width=0.7\textwidth]{Pictures/externalPulse_700.png} 
	\caption[External laser pulse at \texttt{t = 700 * pow(10, 7)}]{External laser pulse at \texttt{t = 700 * pow(10, 7)}. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
	\label{fig: external Pulse}
\end{figure}
\noindent
The idea is to slowly increase $\gamma$ while maintaining a small angle between the particle and the incoming external laser pulse. With increasing $\gamma$ the direction of the radiated Liénard Wiechert field should become more more directed. Similarly, the radiation  frequency should increase as well. Using increments of $\Delta \gamma = 0.1$ we increased $\gamma$ from $\gamma = 1.0$ up to $\gamma = 1.5$. To analyze the radiation direction and radiation frequency we made a Fourier Analysis of the electric field components $\vec{E}$ and of the components of the Poynting vector $\vec{S}$. Figures \ref{fig: plain result gamma1.0} - \ref{fig: ratio gamma1.5} show the plain simulation results, both with and without the near field region of the particle. The ratio of damping Force $g^{\mu}$ and Lorentz force was also calculated at each time step. This way it is easy to show that the damping term $g^{\mu}$ can be neglected.

% plain gamma = 1.0
\begin{figure}[H]
\subfigure[with near field]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.1_0.01_gamma1.0/plain.png}}\hfill
\subfigure[For convenience the fields in the near field region are plotted as well]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.1_0.01_gamma1.0/plain_nearField.png}}
\caption[Initial Conditions: $\texttt{Particle1->u[1]} = 0.1$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$]{Initial Conditions: $\texttt{Particle1->u[1]} = 0.1$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$. The particle history is calculated for \texttt{t = 400 * pow(10, 7)} prior to the simulation. The pictures are taken at \texttt{t = 1100 * pow(10, 7)}. \\
The electron has an energy of $\gamma = 1.0$. We used the external pulse from above as external field and is therefore not shown here. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
\label{fig: plain result gamma1.0}
\end{figure}
\noindent

\begin{SCfigure}[][h]
  \centering
  \includegraphics[height=5cm]{Pictures/results/0.1_0.01_gamma1.0/dampingTermVSLorentzForce.png}  
  \caption{Ratio of the damping force $g^{\mu}$ and Lorentz force $F_L$ at $\gamma = 1.0$. $g^{\mu}$ was calculated at each time step according to \eqref{eqn: Landau-Lifschitz}. Obviously, the damping term $g^{\mu}$ can be neglected.
  Time is in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
  \label{fig: ratio gamma1.0}
\end{SCfigure}
\noindent

% plain gamma = 1.1
\begin{figure}[H]
\subfigure[with near field]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.46_0.01_gamma1.1/plain.png}}\hfill
\subfigure[For convenience the fields in the near field region are plotted as well]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.46_0.01_gamma1.1/plain_nearField.png}}
\caption[Initial Conditions: $\texttt{Particle1->u[1]} = 0.46$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$]{Initial Conditions: $\texttt{Particle1->u[1]} = 0.46$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$. The particle history is calculated for \texttt{t = 400 * pow(10, 7)} prior to the simulation. The pictures are taken at \texttt{t = 1100 * pow(10, 7)}. \\
The electron has an energy of $\gamma = 1.1$. We used the external pulse from above as external field and is therefore not shown here. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
\label{fig: plain result gamma1.1}
\end{figure}
\noindent

\begin{SCfigure}[][h]
  \centering
  \includegraphics[height=5cm]{Pictures/results/0.46_0.01_gamma1.1/dampingTermVSLorentzForce.png}  
  \caption{Ratio of the damping force $g^{\mu}$ and Lorentz force $F_L$ at $\gamma = 1.1$. $g^{\mu}$ was calculated at each time step according to \eqref{eqn: Landau-Lifschitz}. Obviously, the damping term $g^{\mu}$ can be neglected.
  Time is in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
  \label{fig: ratio gamma1.1}
\end{SCfigure}
\noindent

% plain gamma = 1.2
\begin{figure}[H]
\subfigure[with near field]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.67_0.01_gamma1.2/plain.png}}\hfill
\subfigure[For convenience the fields in the near field region are plotted as well]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.67_0.01_gamma1.2/plain_nearField.png}}
\caption[Initial Conditions: $\texttt{Particle1->u[1]} = 0.67$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$]{Initial Conditions: $\texttt{Particle1->u[1]} = 0.67$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$. The particle history is calculated for \texttt{t = 400 * pow(10, 7)} prior to the simulation. The pictures are taken at \texttt{t = 1100 * pow(10, 7)}. \\
The electron has an energy of $\gamma = 1.2$. We used the external pulse from above as external field and is therefore not shown here. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
\label{fig: plain result gamma1.2}
\end{figure}
\noindent

\begin{SCfigure}[][h]
  \centering
  \includegraphics[height=5cm]{Pictures/results/0.67_0.01_gamma1.2/dampingTermVSLorentzForce.png}  
  \caption{Ratio of the damping force $g^{\mu}$ and Lorentz force $F_L$ at $\gamma = 1.2$. $g^{\mu}$ was calculated at each time step according to \eqref{eqn: Landau-Lifschitz}. Obviously, the damping term $g^{\mu}$ can be neglected.
  Time is in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
  \label{fig: ratio gamma1.2}
\end{SCfigure}
\noindent

% plain gamma = 1.3
\begin{figure}[H]
\subfigure[with near field]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.84_0.01_gamma1.3/plain.png}}\hfill
\subfigure[For convenience the fields in the near field region are plotted as well]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.84_0.01_gamma1.3/plain_nearField.png}}
\caption[Initial Conditions: $\texttt{Particle1->u[1]} = 0.84$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$]{Initial Conditions: $\texttt{Particle1->u[1]} = 0.84$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$. The particle history is calculated for \texttt{t = 400 * pow(10, 7)} prior to the simulation. The pictures are taken at \texttt{t = 1100 * pow(10, 7)}. \\
The electron has an energy of $\gamma = 1.3$. We used the external pulse from above as external field and is therefore not shown here. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
\label{fig: plain result gamma1.3}
\end{figure}
\noindent

\begin{SCfigure}[][h]
  \centering
  \includegraphics[height=5cm]{Pictures/results/0.84_0.01_gamma1.3/dampingTermVSLorentzForce.png}  
  \caption{Ratio of the damping force $g^{\mu}$ and Lorentz force $F_L$ at $\gamma = 1.3$. $g^{\mu}$ was calculated at each time step according to \eqref{eqn: Landau-Lifschitz}. Obviously, the damping term $g^{\mu}$ can be neglected.
  Time is in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
  \label{fig: ratio gamma1.3}
\end{SCfigure}
\noindent


% plain gamma = 1.4
\begin{figure}[H]
\subfigure[with near field]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.98_0.01_gamma1.4/plain.png}}\hfill
\subfigure[For convenience the fields in the near field region are plotted as well]{\includegraphics[width=0.49\textwidth]{Pictures/results/0.98_0.01_gamma1.4/plain_nearField.png}}
\caption[Initial Conditions: $\texttt{Particle1->u[1]} = 0.98$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$]{Initial Conditions: $\texttt{Particle1->u[1]} = 0.98$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$. The particle history is calculated for \texttt{t = 400 * pow(10, 7)} prior to the simulation. The pictures are taken at \texttt{t = 1100 * pow(10, 7)}. \\
The electron has an energy of $\gamma = 1.4$. We used the external pulse from above as external field and is therefore not shown here. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
\label{fig: plain result gamma1.4}
\end{figure}
\noindent

\begin{SCfigure}[][h]
  \centering
  \includegraphics[height=5cm]{Pictures/results/0.98_0.01_gamma1.4/dampingTermVSLorentzForce.png}  
  \caption{Ratio of the damping force $g^{\mu}$ and Lorentz force $F_L$ at $\gamma = 1.4$. $g^{\mu}$ was calculated at each time step according to \eqref{eqn: Landau-Lifschitz}. Obviously, the damping term $g^{\mu}$ can be neglected.
  Time is in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
  \label{fig: ratio gamma1.4}
\end{SCfigure}
\noindent

% plain gamma = 1.5
\begin{figure}[H]
\subfigure[with near field]{\includegraphics[width=0.49\textwidth]{Pictures/results/1.12_0.01_gamma1.5/plain.png}}\hfill
\subfigure[For convenience the fields in the near field region are plotted as well]{\includegraphics[width=0.49\textwidth]{Pictures/results/1.12_0.01_gamma1.5/plain_nearField.png}}
\caption[Initial Conditions: $\texttt{Particle1->u[1]} = 1.12$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$]{Initial Conditions: $\texttt{Particle1->u[1]} = 1.12$, $\texttt{Particle1->u[2] = 0.01}$ and $\texttt{Particle1->u[3] = 0.0}$. The particle history is calculated for \texttt{t = 400 * pow(10, 7)} prior to the simulation. The pictures are taken at \texttt{t = 1100 * pow(10, 7)}. \\
The electron has an energy of $\gamma = 1.5$. We used the external pulse from above as external field and is therefore not shown here. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
\label{fig: plain result gamma1.5}
\end{figure}
\noindent

\begin{SCfigure}[][h]
  \centering
  \includegraphics[height=5cm]{Pictures/results/1.12_0.01_gamma1.5/dampingTermVSLorentzForce.png}  
  \caption{Ratio of the damping force $g^{\mu}$ and Lorentz force $F_L$ at $\gamma = 1.5$. $g^{\mu}$ was calculated at each time step according to \eqref{eqn: Landau-Lifschitz}. Obviously, the damping term $g^{\mu}$ can be neglected.
  Time is in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
  \label{fig: ratio gamma1.5}
\end{SCfigure}
\noindent
In the next step the electric field components $\vec{E}$ as well as the Poynting vector $\vec{S}$ are 2D Fourier analyzed. The results are shown in figures \ref{fig: E fourier gamma1.0} - \ref{fig: E fourier gamma1.5}

% fourier gamma = 1.0
\begin{figure}[H]
\centering
\subfigure[]{\includegraphics[width=0.8\textwidth]{Pictures/results/0.1_0.01_gamma1.0/fourierAnalysis2D.png}}
\subfigure[]{\includegraphics[width=0.8\textwidth]{Pictures/results/0.1_0.01_gamma1.0/fourierAnalysisPoynting2D.png}}
\caption[Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.0$]{Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.0$. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
	\label{fig: E fourier gamma1.0}
\end{figure}
\noindent

% fourier gamma = 1.1
\begin{figure}[H]
\centering
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/0.46_0.01_gamma1.1/fourierAnalysis2D.png}}
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/0.46_0.01_gamma1.1/fourierAnalysisPoynting2D.png}}
\caption[Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.1$]{Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.1$. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
	\label{fig: E fourier gamma1.1}
\end{figure}
\noindent

% fourier gamma = 1.2
\begin{figure}[H]
\centering
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/0.67_0.01_gamma1.2/fourierAnalysis2D.png}}
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/0.67_0.01_gamma1.2/fourierAnalysisPoynting2D.png}}
\caption[Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.2$]{Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.2$. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
	\label{fig: E fourier gamma1.2}
\end{figure}
\noindent

% fourier gamma = 1.3
\begin{figure}[H]
\centering
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/0.84_0.01_gamma1.3/fourierAnalysis2D.png}}
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/0.84_0.01_gamma1.3/fourierAnalysisPoynting2D.png}}
\caption[Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.3$]{Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.3$. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
	\label{fig: E fourier gamma1.3}
\end{figure}
\noindent

% fourier gamma = 1.4
\begin{figure}[H]
\centering
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/0.98_0.01_gamma1.4/fourierAnalysis2D.png}}
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/0.98_0.01_gamma1.4/fourierAnalysisPoynting2D.png}}
\caption[Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.4$]{Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.4$. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
	\label{fig: E fourier gamma1.4}
\end{figure}
\noindent

% fourier gamma = 1.5
\begin{figure}[H]
\centering
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/1.12_0.01_gamma1.5/fourierAnalysis2D.png}}
\subfigure[]{\includegraphics[width=0.9\textwidth]{Pictures/results/1.12_0.01_gamma1.5/fourierAnalysisPoynting2D.png}}
\caption[Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.5$]{Fourier analysis of (a) the electric field components of $\vec{E}$ and (b) the components of the Poynting vector $\vec{S}$ at $\gamma = 1.5$. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$.}
	\label{fig: E fourier gamma1.5}
\end{figure}
\noindent
From the Fourier Analysis of the electric field components, especially from the $E_y$ component, in the figures \ref{fig: E fourier gamma1.0} - \ref{fig: E fourier gamma1.5} one can clearly see an increase in frequency of the radiated fields. There is a main peak moving from low frequencies to high frequencies along the $\omega_x$-axis as $\gamma$ is increasing. This behavior is as expected from Section \ref{sec: Energy emission}. The particle is first directed into x-direction. While interacting with the laser pulse the particle changes its trajectory and is therefore accelerated, causing Liénard Wiechert fields to be radiated parallel to the direction of acceleration. Whereas at low energies the trajectory of the particle tends more towards y-direction the trajectory tends more towards x-direction at higher energies. This is because the  time the particle interacts with the laser pulse decreases with higher values of $\gamma$. The less time the particle interacts with the laser pulse, the less it gets deflected in y-direction.Therefore, $\omega_y$ frequencies appear more often at lower than at higher values of $\gamma$. The same argumentation holds for the Fourier Analysis of the Poynting vector $\vec{S}$. As the Liénard Wiechert fields become more and more directed into x-direction with increasing $\gamma$, the energy flux $\vec{S}$ becomes also more directed. 
%======================== UPML ============================
%===========================================================
\chapter{Uniaxial Perfectly Matched Layer}
\section{Introduction}
In this chapter we want to discuss an important topic: Boundary Conditions. \\
Boundary Conditions apply at the edge of the numerical grid and dictate how the solution is treated, when approaching the edge. The Dirichlet boundary condition, for instance, sets the solution to zero, leading to reflections \footnote{It's like a rope with a fixed connection to a wall. Since the energy can not be transferred to the wall, all energy is reflected, causing the incident wave to move back. }. Periodic boundary conditions extend the grid by setting one edge on top of the opposite one. Solutions leaving the grid to the right enter the simulation area to the left again. \\ 
When solving differential equations numerically one always has to think about which boundary conditions apply best for the problem at hand. The most commonly used ones are the two aforementioned ones. Dirichlet boundary conditions apply for physical problems involving fast decaying solutions in space so that truncation does not matter, as long as the numerical grid is large enough. Other problems, like periodic structures, can be simulated with periodic boundary conditions. However, one of the most challenging problems to truncate involve wave equations, like in our case, since their solution only decays slowly \footnote{Energy conservation requires the energy flux $|S| \propto |E|^2$ to decay inversly proportional to the surface area $\sim r^2$ in three dimensions. Therefore, $|E| \propto \frac{1}{r}$.}. Using periodic, Dirichlet or Neumann boundary conditions will lead to unacceptable artifacts from boundary reflections. One approach is the \textit{absorbing boundary condition} \cite{Taflove}. It turns out that this approach works just fine for the one dimensional case, i.e. waves traveling in only one direction. However, most problems - like ours - include three dimensions. So, we are left where we started. Fortunately in 1994 Berenger came up with a new idea and presented it in his seminal paper \cite{Berenger}. Instead of having an absorbing boundary condition he rather proposed an absorbing boundary layer. The layer is part of the grid and has a specified width. When a wave enters the layer, it is attenuated by the absorption and decays exponentially. Now the problems remains, that the absorbing layer represents and interface where the impedance change, which in turn causes reflection and transmission. Berenger, however, showed that it's possible to construct a medium which does not reflect any incident wave, independent of angle, polarization and frequency. A so called PML - \textit{Perfectly Matched Layer}. Aside from Berenger's  original formulation -the \textit{split field} PML -  some equivalent descriptions of PML came up over the years. For one there are the \textit{uniaxial} PML (UPML) which we use in this thesis and dive into more detail below. The most elegant and general description is the \textit{stretched coordinate} PML \cite{Chew, Rappaport, Teixeira}, which is based upon an analytic continuation of Maxwell`s equations into complex spatial coordinates. Both the split field PML and the UPML can be derived from this approach.\\

%======================== Derivation ============================
\section{Derivation}
The most common formulation is the UPML. Following \cite{Taflove, CEM} we will present an overview of the most important steps to understand why UPML works and how to implement it. \\
It will turn out that the medium inside our PML needs to be anisotropic. We will see why later. Being able to describe anisotropic phenomenon we need to incorporate anisotropy into Maxwell Equations. We can do this by making the permittivity $\epsilon_r$ and permeability $\mu_r$ tensors \footnote{There are three types of anisotropic media: \\
isotropic:
$ \begin{bmatrix}
a & 0 & 0  \\
0 & a &0  \\
0 & 0 & a 
\end{bmatrix}$, 
uniaxial: 
$ \begin{bmatrix}
a & 0 & 0  \\
0 & a &0  \\
0 & 0 & b 
\end{bmatrix}$,
biaxial:
$ \begin{bmatrix}
a & 0 & 0  \\
0 & b &0  \\
0 & 0 & c 
\end{bmatrix}$.\\
It is also possible to always choose a coordinate system such that the tensor becomes diagonal.}. 
The time harmonic Maxwell's Curl equations then read
\beq
\bal
\label{eqn: frequencyDomainMaxwellEquations}
\vec{\nabla} \times \vec{E}(\omega) &= -j\omega\mu_0\left[\mu_r\right]\vec{H}(\omega), \\
\vec{\nabla} \times \vec{H}(\omega) &= \sigma \vec{E}(\omega) + j\omega\vec{D}(\omega),
\eal
\eeq
with the relation $\vec{D}(\omega) = \epsilon_0\left[\epsilon_r\right]\vec{E}$ and conductivity $\sigma$. As usual, $\epsilon_0$ and $\epsilon_r$ are the vacuum and relative permittivity respectively. We start in the frequency domain, because PML is a frequency domain concept and thus it's easier to work with in frequency domain. We will, however, transform back to time domain later in order to get the update equations, which we will need to implement. So, \eqref{eqn: frequencyDomainMaxwellEquations} can be rewritten as
\beq
\bal
\begin{pmatrix}
0 & - \frac{\del}{\del z} & \frac{\del}{\del y}  \\
\frac{\del}{\del z} & 0 & -\frac{\del}{\del x}  \\
- \frac{\del}{\del y} & \frac{\del}{\del x} & 0
\end{pmatrix}
\begin{pmatrix}
H_x \\ 
H_y \\
H_z
\end{pmatrix}
&= j\omega\epsilon_0 
\begin{bmatrix}
\epsilon_x + \frac{\sigma^E_x}{j\omega} & 0 & 0  \\
0 & \epsilon_y + \frac{\sigma^E_y}{j\omega}  & 0 \\
0 & 0 & \epsilon_z + \frac{\sigma^E_z}{j\omega} 
\end{bmatrix}
\begin{pmatrix}
E_x \\ 
E_y \\
E_z
\end{pmatrix} 
\\
\begin{pmatrix}
0 & - \frac{\del}{\del z} & \frac{\del}{\del y}  \\
\frac{\del}{\del z} & 0 & -\frac{\del}{\del x}  \\
- \frac{\del}{\del y} & \frac{\del}{\del x} & 0
\end{pmatrix}
\begin{pmatrix}
E_x \\ 
E_y \\
E_z
\end{pmatrix}
&= - j\omega\mu_0 
\begin{bmatrix}
\mu_x + \frac{\sigma^H_x}{j\omega} & 0 & 0  \\
0 & \mu_y + \frac{\sigma^H_y}{j\omega}  & 0 \\
0 & 0 & \mu_z + \frac{\sigma^H_z}{j\omega} 
\end{bmatrix}
\begin{pmatrix}
H_x \\ 
H_y \\
H_z
\end{pmatrix} 
\eal
\eeq
Now we need to talk about reflection and transmission at a surface. 
%First we start off with the reflection and transmission of an incident wave at a lossy surface. Let $n$ be the ordinary refractive index and $\kappa$ the extinction coefficient. then the complex refractive index is
%\beq
%N = n + j\kappa,
%\eeq
%where $j$ denotes the imaginary unit. From Optics we know, that the reflection $R$ can be expressed as
%\beq
%R = \frac{(1-n)^2 + \kappa^2}{(1+n)^2 + \kappa^2}.
%\eeq
%Notice, that not the refractive index alone, but also the loss contributes to reflection. 
In the case of a wave with arbitrary polarization and angle of incidence, as illustrated in Figure \ref{fig: Fresnel}, we can use \textit{Fresnel} equations. \footnote{
\beq
\bal
r_{TE} &= \frac{\eta_2 \cos(\theta_1) - \eta_1\cos(\theta_2)}{\eta_2 \cos(\theta_1) + \eta_1\cos(\theta_2)}, \\
t_{TE} &= \frac{2\eta_2 \cos(\theta_1)}{\eta_2 \cos(\theta_1) + \eta_1\cos(\theta_2)}, \\
r_{TM} &= \frac{\eta_2 \cos(\theta_2) - \eta_1\cos(\theta_1)}{\eta_1 \cos(\theta_1) + \eta_2\cos(\theta_2)}, \\
t_{TM} &= \frac{2\eta_1 \cos(\theta_1)}{\eta_1 \cos(\theta_1) + \eta_2\cos(\theta_2)},
\eal
\eeq
where $\eta_i$ is the impedance in region $i$ with refractive index $n_i$, $\theta_1$ the angle of incidence and $\theta_2$ the angle of transmission.}
We see that the reflection is a consequence of a change in impedance and also critically angle dependent. It's only possible to match the impedances at one specific angle. However, by introducing anisotropy we can solve this problem. We know that the impedance is given by
\beq
\eta = \sqrt{\frac{\mu}{\epsilon}}.
\eeq
Thus, to keep the impedances matched throughout the entire grid, including the absorbing layer, we need $\left[\epsilon_r\right] = \left[\mu_r\right]$. This is called an doubly anisotropic media. For convenience let's define
\beq
\left[s\right] \coloneqq \left[\epsilon_r\right] = \left[\mu_r\right] = 
\begin{bmatrix}
a & 0 & 0  \\
0 & b &0  \\
0 & 0 & c 
\end{bmatrix},
\eeq
with $a, b, c$ to be determined. Considering anisotropy the Fresnel Equations change. For example for an incident wave traveling along z-axis, the Fresnel Equations read
\begin{figure}[t]
	\centering
		\includegraphics[width=0.5\textwidth]{Pictures/Fresnel.png} 
	\caption[Wave with wavevector $\vec{k}$, arbitrary polarization and angle of incidence $\theta$ at a surface with impedance $\eta_i$ and refractive index $n_i$]{Wave with wavevector $\vec{k}$, arbitrary polarization and angle of incidence $\theta$ at a surface with impedance $\eta_i$ and refractive index $n_i$ \cite{CEM}.}
	\label{fig: Fresnel}
\end{figure}
\noindent
\beq
\bal
\label{eqn: Fresnel}
r_{TE} &= \frac{\sqrt{a} \cos(\theta_1) - \sqrt{b}\cos(\theta_2)}{\sqrt{a} \cos(\theta_1) + \sqrt{b}\cos(\theta_2)}, \\
t_{TE} &= \frac{\sqrt{a} \cos(\theta_1)}{\sqrt{a} \cos(\theta_1) + \sqrt{b}\cos(\theta_2)}, \\
r_{TM} &= \frac{-\sqrt{a} \cos(\theta_1) + \sqrt{b}\cos(\theta_2)}{\sqrt{a} \cos(\theta_1) + \sqrt{b}\cos(\theta_2)}, \\
t_{TM} &= \frac{\sqrt{a} \cos(\theta_1)}{\sqrt{b} \cos(\theta_1) + \sqrt{a}\cos(\theta_2)},
\eal
\eeq
where $\theta_1$ the angle of incidence and $\theta_2$ the angle of transmission. These two are connected via Snell's Law
\beq
\sin(\theta_1) = \sqrt{bc}\sin{\theta_2}.
\eeq
We now need to find conditions for $a,b,c$ to make the Fresnel equations \eqref{eqn: Fresnel} independent of angle and simultaneously let the reflection parameter vanish. \\
If we choose $\sqrt{bc} = 1$ Snell's Law simplifies to $\theta_1 = \theta_2$. Thus the reflection parameters reduce to
\beq
\bal
r_{TE} &= \frac{\sqrt{a} - \sqrt{b}}{\sqrt{a} + \sqrt{b}}, \\
r_{TM} &= \frac{-\sqrt{a} + \sqrt{b}}{\sqrt{a} + \sqrt{b}}.
\eal
\eeq
With this choice we made the reflection independent of angle! Furthermore, if we require $r_{TE} \stackrel{!}{=} 0$ and $r_{TM} \stackrel{!}{=} 0$ we get $a \stackrel{!}{=} b$. To sum it up, $a, b, c$ need to fulfill 
\beq
a = b = \frac{1}{c}.
\eeq
Therefore, our tensor $\left[s_z\right]$ needs to look like this
\beq
\left[s_z\right] = 
\begin{bmatrix}
s_z & 0 & 0  \\
0 & s_z &0  \\
0 & 0 & \frac{1}{s_z} 
\end{bmatrix}.
\eeq
Recall that this is an uniaxial tensor. This is the reason why this approach is called Uniaxial Perfectly Matched Layer. \\
Analogously one gets
\beq
\bal
\left[s_y\right] = 
\begin{bmatrix}
s_y & 0 & 0  \\
0 & \frac{1}{s_z} &0  \\
0 & 0 & s_y 
\end{bmatrix}~
\text{and}~
\left[s_x\right] = 
\begin{bmatrix}
\frac{1}{s_z} & 0 & 0  \\
0 & s_x &0  \\
0 & 0 & s_x 
\end{bmatrix},
\eal
\eeq
for waves traveling in $y$ and $x$ direction respectively. These can be combined in a single tensor \cite{Taflove}
\beq
\left[s\right] \coloneqq \left[s_x\right] \left[s_y\right] \left[s_z\right] = 
\begin{bmatrix}
\frac{s_ys_z}{s_x} & 0 & 0  \\
0 & \frac{s_xs_z}{s_y} &0  \\
0 & 0 & \frac{s_xs_y}{s_z} 
\end{bmatrix},
\eeq
where 
\beq
\bal
\label{eqn: s-factors}
s_x(x) = \kappa_x + \frac{\sigma^{'}_x(x)}{j\omega_0\epsilon_0} \\
s_y(y) = \kappa_y + \frac{\sigma^{'}_y(y)}{j\omega_0\epsilon_0}\\
s_z(z) = \kappa_z + \frac{\sigma^{'}_z(z)}{j\omega_0\epsilon_0}.
\eal
\eeq
We will specify $\sigma^{'}$ and $\kappa$ later. Having this, the Maxwell Equations \eqref{eqn: frequencyDomainMaxwellEquations} now read
\beq
\bal
\label{eqn: frequencyDomainMaxwellEquationsWithPML}
\vec{\nabla} \times \vec{E}(\omega) &= -j\omega\mu_0\left[\mu_r\right]\left[s\right]\vec{H}(\omega), \\
\vec{\nabla} \times \vec{H}(\omega) &= \sigma \vec{E}(\omega) + j\omega\left[s\right]\vec{D}(\omega).
\eal
\eeq
Before we start to derive the update equations, we normalize our electric field as follows
\beq
\bal
\vec{\tilde{E}} = \sqrt{\frac{\epsilon_0}{\mu_0}} \vec{E} = \frac{1}{\eta_0} \vec{E} \\
\vec{\tilde{D}} = \frac{1}{\sqrt{\mu_0\epsilon_0}}\vec{E} = c_0\vec{E},
\eal
\eeq
which yields 
\beq
\bal
\label{eqn: frequencyDomainMaxwellEquationsWithPML}
\vec{\nabla} \times \vec{\tilde{E}}(\omega) &= -j\omega\mu_0\frac{\left[\mu_r\right]}{c_0}\left[s\right]\vec{H}(\omega), \\
\vec{\nabla} \times \vec{H}(\omega) &= \eta_0\sigma \vec{\tilde{E}}(\omega) + \frac{j\omega}{c_0}\left[s\right]\vec{\tilde{D}}(\omega).
\eal
\eeq

%======================== Update Equations ============================
\section{Update Equations}
We now want to derive the update equations from \eqref{eqn: frequencyDomainMaxwellEquationsWithPML}. For simplicity we focus on Ampere's Law and consider the case, where the interior of our simulation area has no loss ($\sigma = 0$). Only the PML will have loss ($\sigma^{'} \neq 0$).
Ampere's Law rewritten in matrix form then simplifies to
\beq
\label{eqn: Ampere's Law}
\begin{pmatrix}
\frac{\del H_z}{\del y} - \frac{\del H_y}{\del z}   \\
\frac{\del H_x}{\del z} - \frac{\del H_z}{\del x}   \\
\frac{\del H_y}{\del x} - \frac{\del H_x}{\del y}
\end{pmatrix}
=
j\omega 
\begin{bmatrix}
s_x & 0 & 0  \\
0 & s_y &0  \\
0 & 0 & s_z
\end{bmatrix}
\begin{pmatrix}
\tilde{Dx} \\
\tilde{Dy} \\
\tilde{Dz} 
\end{pmatrix}.
\eeq
Substituting \eqref{eqn: s-factors} into \eqref{eqn: Ampere's Law} and using the fourier identity 
\beq
\mathcal{F}\left\{\frac{\del^n}{\del t^n} g(t)\right\} = (j\omega)^n G(\omega),
\eeq
where $g$ is a piecewise $\mathcal{C}^{1}$ function and $g \in \mathcal{L}^{1}(\mathbb{R})$ yields the following system of time domain equations
\beq
\label{eqn: Ampere's Law in time domain}
\begin{pmatrix}
\frac{\del H_z}{\del y} - \frac{\del H_y}{\del z}   \\
\frac{\del H_x}{\del z} - \frac{\del H_z}{\del x}   \\
\frac{\del H_y}{\del x} - \frac{\del H_x}{\del y}
\end{pmatrix}
=
\frac{\del}{\del t}
\begin{bmatrix}
\kappa_x & 0 & 0  \\
0 & \kappa_y &0  \\
0 & 0 & \kappa_z
\end{bmatrix}
\begin{pmatrix}
\tilde{Dx} \\
\tilde{Dy} \\
\tilde{Dz} 
\end{pmatrix}
+
\frac{1}{\epsilon_0}
\begin{bmatrix}
\sigma^{'}_x & 0 & 0  \\
0 & \sigma^{'}_y &0  \\
0 & 0 & \sigma^{'}_z
\end{bmatrix}
\begin{pmatrix}
\tilde{Dx} \\
\tilde{Dy} \\
\tilde{Dz} 
\end{pmatrix}.
\eeq
The system \eqref{eqn: Ampere's Law in time domain} can be discretized with Yee-Scheme, as explained in Section \ref{sec: Yee-Scheme} and using central differences. Because it's quite longish and a lot's of Algebra we ommitt it here and refer to literature instead (see \cite{Taflove, CEM}). For instance, the $D_x$ update is given by
\begin{multline}
\label{eqn: updateD}
\textcolor{red}{D_x\Bigr|_{(i+\frac{1}{2},j,k)}^{n+1}} = \left(\frac{2\epsilon_0\kappa_y - \sigma^{'}_y h}{2\epsilon_0\kappa_y + \sigma^{'}_y h}\right) D_x\Bigr|_{i+\frac{1}{2},j,k}^{n} + \left(\frac{2\epsilon_0 h}{2\epsilon_0\kappa_y + \sigma^{'}_y h}\right) \\
 \left( \frac{H_z\Bigr|^{n+\frac{1}{2}}_{(i+\frac{1}{2},j+\frac{1}{2},k)} - H_z\Bigr|^{n+\frac{1}{2}}_{(i+\frac{1}{2},j-\frac{1}{2},k)}}{\Delta y} - \frac{H_y\Bigr|^{n+\frac{1}{2}}_{(i+\frac{1}{2},j,k+\frac{1}{2})} - H_y\Bigr|^{n+\frac{1}{2}}_{(i+\frac{1}{2},j,k-\frac{1}{2})}}{\Delta z}\right).
\end{multline}
From $\vec{D}(\omega) = \epsilon_0\left[\epsilon_r\right]\vec{E}$ the update equation for $\vec{E}$ can be derived
\begin{multline}
\label{eqn: updateE}
E_x\Bigr|_{(i+\frac{1}{2},j,k)}^{n+1} = \left(\frac{2\epsilon_0\kappa_z - \sigma^{'}_z h}{2\epsilon_0\kappa_z + \sigma^{'}_z h}\right) E_x\Bigr|_{i+\frac{1}{2},j,k}^{n} + \left(\frac{1}{(2\epsilon_0\kappa_z + \sigma^{'}_z h) \epsilon}\right) \\
 \left( (2\epsilon_0\kappa_x + \sigma^{'}_x h) \textcolor{red}{D_x\Bigr|_{i+\frac{1}{2},j,k}^{n+1}} - (2\epsilon_0\kappa_x - \sigma^{'}_x h) D_x\Bigr|_{i+\frac{1}{2},j,k}^{n}\right).
\end{multline}
As we can see, the update equation for $E_x\Bigr|_{(i+\frac{1}{2},j,k)}^{n+1}$ contains the term $\textcolor{red}{D_x\Bigr|_{i+\frac{1}{2},j,k}^{n+1}}$. Consequently the update process of $E_x$ requires an update of $D_x$ first. So, we first calculate $D_x$ for the next time step and use this result to update $E_x$. The same procedure applies for the update equations of $B_x$ and $H_x$
\begin{multline}
\label{eqn: updateB}
\textcolor{blue}{B_x\Bigr|_{(i,j+\frac{1}{2},k+\frac{1}{2})}^{n+\frac{3}{2}}} = \left(\frac{2\epsilon_0\kappa_y - \sigma^{'}_y h}{2\epsilon_0\kappa_y + \sigma^{'}_y h}\right) B_x\Bigr|_{(i,j+\frac{1}{2},k+\frac{1}{2})}^{n+\frac{1}{2}} + \left(\frac{2\epsilon_0 h}{2\epsilon_0\kappa_y + \sigma^{'}_y h}\right) \\
 \left( \frac{E_z\Bigr|^{n+1}_{(i,j+1,k+\frac{1}{2})} - E_z\Bigr|^{n+1}_{(i,j,k+\frac{1}{2})}}{\Delta y} - \frac{E_y\Bigr|^{n+1}_{(i,j+\frac{1}{2},k+1)} - E_y\Bigr|^{n+1}_{(i,j+\frac{1}{2},k)}}{\Delta z}\right),
\end{multline}
\begin{multline}
\label{eqn: updateH}
H_x\Bigr|_{(i,j+\frac{1}{2},k+\frac{1}{2})}^{n+\frac{3}{2}}= \left(\frac{2\epsilon_0\kappa_z - \sigma^{'}_z h}{2\epsilon_0\kappa_z + \sigma^{'}_z h}\right) H_x\Bigr|_{(i,j+\frac{1}{2},k+\frac{1}{2})}^{n+\frac{1}{2}} + \left(\frac{1}{(2\epsilon_0\kappa_z + \sigma^{'}_z h) \mu}\right) \\
 \left( (2\epsilon_0\kappa_x + \sigma^{'}_x h) \textcolor{blue}{B_x\Bigr|_{(i,j+\frac{1}{2},k+\frac{1}{2})}^{n+\frac{3}{2}}} - (2\epsilon_0\kappa_x - \sigma^{'}_x h) B_x\Bigr|_{i,j+\frac{1}{2},k+\frac{1}{2}}^{n+\frac{1}{2}}\right).
\end{multline}
Notice that if we turn off the PML, i.e. $\sigma^{'} = 0$ and $\kappa = 1$ the prefactors simplify drastically. Plugging in \eqref{eqn: updateD} into \eqref{eqn: updateE} and also \eqref{eqn: updateB} into \eqref{eqn: updateH} result in the discretized Maxwell Equations, as we derived them in \eqref{eqn: discreteMaxwellEq}. Of course, the update equations of the other field components can be derived analogously. 

%======================== Implementation of UPML in FDTD ============================
\section{Implementation of UPML in FDTD}
Finally, we want to show, how to implement UPML into an existing FDTD simulation. Since all the prefactors are constants, it's advisable to calculate them beforehand. Here is a snippet of the code
\begin{lstlisting}
Grid->upml1E[j] = (2 * kappa - sigma * dt) / (2 * kappa + sigma * dt);
Grid->upml2E[j] = (2 * dt) / (2 * kappa + sigma * dt);
Grid->upml3E[k] = (2 * kappa - sigma * dt) / (2 * kappa + sigma * dt);
Grid->upml4E[k] = 1.0 / (2 * kappa + sigma * dt);
Grid->upml5E[i] = (2 * kappa + sigma * dt);
Grid->upml6E[i] = (2 * kappa - sigma * dt);
\end{lstlisting}
The same applies for the H components. \\
From a theoretical point of view, a reflectionless PML is possible. In practice, however, numerical artifacts arise, due to finite spatial sampling \cite{Taflove}. The change from $\sigma$ in the interior to $\sigma^{'}$ in the PML is effectively a local discontinuity and thus causes reflections. For best performance, Berenger proposed that the PML losses $\sigma^{'}$ shall gradually rise from zero at $x = 0$ to $\sigma_{max}$ at $x = d$, where $d$ is the PML layer width \cite{Berenger}
\beq
\bal
\sigma_x(x) &= \left(\frac{x}{d}\right)^{m} \sigma_{x,max} \\
\kappa_x(x) &= 1+ \left(\kappa_{x,max} - 1\right)  \left(\frac{x}{d}\right)^{m}.
\eal
\eeq
m defines the grading and is typically $3 \le m \le 4$ in FDTD simulations. We chose $m = 3.5$. Through a lot of testing and experimenting, $\sigma_{max}$ was found to be \cite{Taflove}
\beq
\label{eqn: sigmaMaxOpt}
\sigma_x^{opt} = \frac{0.8 (m+1)}{\eta \Delta x},
\eeq
where $\eta = \sqrt{\frac{\mu}{\epsilon}}$. This of course also applies for the other components of $\sigma$. \\
Figure \ref{fig: upml} shows how a simulation with UPML looks like

\begin{figure}[H]
\subfigure[$\texttt{t} = 11$]{\includegraphics[width=0.33\textwidth]{Pictures/upml_11.png}}\hfill
\subfigure[$\texttt{t} = 15.75$]{\includegraphics[width=0.33\textwidth]{Pictures/upml_15_75.png}}\hfill
\subfigure[$\texttt{t} = 18$]{\includegraphics[width=0.33\textwidth]{Pictures/upml_18.png}}
\caption[Simulation using UPML]{Simulation using UPML.\\  
The electron has an energy of $\gamma = 1.2$. We used a constant $B_z = 1$ as external field. The colorbar shows the value of $|\vec{E}|^2$. $\vec{E}$ and $c\vec{B}$ are in units of $4\pi\epsilon_0m_e^2c^4/e^3 = 1.77 \cdot 10^{20} \si{\volt\per\meter}$, length in units of $e^2 / (4\pi\epsilon_0m_ec^2) = 2.82 \cdot 10^{-15}\si{\meter}$ and times in units of $e^2 / (4\pi\epsilon_0m_ec^3) = 9.40 \cdot 10^{-24}\si{\second}$}	
\label{fig: upml}
\end{figure}
\noindent
%======================== Summary ============================
%===========================================================
\part{Summary \& Outlook}
This thesis was build upon the Hybrid Field Approach from \cite{Herzing}. The framework, written in \texttt{C++}, was entirely rewritten in \texttt{C} and furthermore extended with new features, like a reverse Boris Push to extend the particle history before the simulation, trilinear Interpolation of fields at the particle position, effective storage of precalculated fields, due to extended particle history and UPML. A stable code base was produced, including Doxygen documentation allowing others to use and extend the code more easily. In order to ensure the proper functionality of the framework, a scattering process of an electron in an electromagnetic wave was simulated. Considering realistic scales made it possible to compare the results with real world experiments. By analyzing the Fourier components of the electric field and the Poynting vector, we could show that with increasing energy $\gamma$ of the electron the radiation frequency increased and the radiation of Liénard Wiechert fields became more directed. \\
\newline
As already outlined in Section \ref{sec: Particle History} the storage of particle positions can be optimized. A plausible criteria for finding the particle position after which all following positions can be neglected has to be velocity dependent. An even better approach would be to define a cutoff distance at which the emitted fields would be attenuated so much, that they be could be neglected. To make large simulations with more than $10^{10}$ particles possible, an effective memory management is absolutely necessary, which makes this point worth looking into.\\
Another point which can be optimized is UPML. Problems occur when Liénard Wiechert fields are calculated from the extended particle history prior to the simulation. If field values are set into the UPML region, the they stay there or even worse, they diverge, causing strange artefacts to occur at the boundaries. One should definitely exclude the UPML layer from the field initialization. Regarding memory consumption, UPMLs can be optimized as well. Arrays are used to store the values for the conductivity $\sigma$ and the extinction coefficient $\kappa$ throughout the grid. Problem being that $\sigma$ and $\kappa$ are constant inside the simulation area or equivalently outside the defined UPML layer width. Having a large number of grid points, this way of storing $\sigma$ and $\kappa$ is highly unfavorable. There is a solution for that problem, as discussed in \cite{Taflove}, at the cost of more complex code. Yet, another problem is to find optimal values for $\sigma_{max}$ and $\kappa_{max}$. Even though there are suggestions for $\sigma$ like equation \eqref{eqn: sigmaMaxOpt}, there are no suggestions for $\kappa$ and still there is a lot of try and error to find the best values.\\

%======================== Appendix ============================
%===========================================================
\part{Appendix}
\appendix

%======================== Gauge Transformations ============================
\chapter{Gauge Transformations}
\label{appendix: Gauge Transformations}
\noindent
In this chapter we want to show, that the gauge fields leave both the electric and magnetic fields and the corresponding potential equations invariant.
\section{Invariance of Fields}
We want to show that $\vec{E}' = \vec{E}$ and $\vec{B}' = \vec{B}$.
\beq
\bal
\vec{E}' &= -\vec{\nabla} \varphi' - \frac{\del \vec{A}'}{\del t} \nn \\
&= -\vec{\nabla} \left( \varphi - \frac{\del \psi}{\del t}\right) - \frac{\del}{\del t}\left( \vec{A} + \vec{\nabla} \psi\right) \nn \\
&= -\vec{\nabla}\varphi + \vec{\nabla}\left(\frac{\del \psi}{\del t}\right) -  \frac{\del \vec{A}}{\del t} - \frac{\del}{\del t} (\vec{\nabla} \psi) \nn\\
&= \vec{E}
\eal
\eeq
and
\beq
\bal
\vec{B}' &= \vec{\nabla} \times \vec{A}' \nn\\
&= \vec{\nabla} \times \left( \vec{A} + \vec{\nabla} \psi\right)\nn\\
&= \vec{\nabla}\times \vec{A} + \vec{\nabla}\times (\vec{\nabla} \psi)\nn\\
&= \vec{B}.
\eal
\eeq

%======================== Invariance of Potential Equations ============================
\section{Invariance of Potential Equations}
Now we want to show the invariance of the potential equations. Therefore, consider
\beq
\bal
-\Delta \varphi' - \vec{\nabla}\left(\frac{\del \vec{A}'}{\del t}\right) &= \frac{\rho}{\epsilon_0} \nn\\
\Longleftrightarrow -\Delta \left(\varphi - \frac{\del \psi}{\del t} \right) - \vec{\nabla}\left[ \frac{\del}{\del t} \left(\vec{A} + \vec{\nabla}\psi\right) \right] &=\frac{\rho}{\epsilon_0} \nn\\
\Longleftrightarrow -\Delta \varphi + \Delta\left(\frac{\del \psi}{\del t}\right) - \vec{\nabla}\left(\frac{\del \vec{A}}{\del t}\right) - \vec{\nabla}\left[ \frac{\del}{\del t}\left( \vec{\nabla}\psi\right) \right] &= \frac{\rho}{\epsilon_0} \nn\\
\Longleftrightarrow -\Delta \varphi - \vec{\nabla}\left(\frac{\del \vec{A}}{\del t}\right) &= \frac{\rho}{\epsilon_0} \nn\\
\eal
\eeq
and
\beq
\bal
\square \vec{A}' - \vec{\nabla} \left(\vec{\nabla} \vec{A}' + \frac{1}{c^2}\frac{\del \varphi' }{\del t} \right) &= -\mu_0\vec{j}\nn\\
\Longleftrightarrow \hat\square \left(\vec{A} + \vec{\nabla}\psi\right) - \vec{\nabla} \left[\vec{\nabla}  \left(\vec{A} + \vec{\nabla}\psi\right) + \frac{1}{c^2}\frac{\del}{\del t} \left(\varphi - \frac{\del \psi}{\del t} \right) \right] &= -\mu_0\vec{j}\nn\\
\Longleftrightarrow \hat\square \vec{A} + \square \left(\vec{\nabla}\psi\right) - \vec{\nabla} \left[\vec{\nabla} \vec{A} + \Delta \psi + \frac{1}{c^2}\frac{\del \varphi}{\del t} -  \frac{1}{c^2}\frac{\del^2 \psi}{\del t^2} \right] &= -\mu_0\vec{j}\nn\\
\Longleftrightarrow \hat\square \vec{A} + \square \left(\vec{\nabla}\psi\right) - \vec{\nabla} \left[\vec{\nabla} \vec{A} + \square \psi +  \frac{1}{c^2}\frac{\del \varphi}{\del t} \right] &= -\mu_0\vec{j}\nn\\
\Longleftrightarrow \hat\square \vec{A} - \vec{\nabla} \left(\vec{\nabla} \vec{A} + \frac{1}{c^2}\frac{\del \varphi}{\del t} \right) &= -\mu_0\vec{j}\nn\\
\eal
\eeq
\chapter{Retarded Potential Equations Fulfill Laurentz Gauge}
\label{appendix: Retarded Potential Equations Fulfill Laurentz Gauge}
\noindent
We show that the retarded potential equations 
\beq
\varphi(\vec{r},t) &=& \frac{1}{4\pi \epsilon_0} \int_{V} \frac{\rho(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{r}~',\nn\\
\vec{A}(\vec{r},t) &=& \frac{\mu_0}{4\pi} \int_{V} \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{r}~'\nn
\eeq
with $t_{ret} \coloneqq t - \frac{|\vec{r} - \vec{r}~'|}{c}$ fulfill the Laurentz Gauge
\beq
\vec{\nabla} \vec{A} + \frac{1}{c^2}\frac{\del \varphi}{\del t} = 0.\nn
\eeq
Plugging in yields
\beq
\label{eqn: step1}
\bal
\vec{\nabla} \vec{A} + \frac{1}{c^2}\frac{\del \varphi}{\del t} &= \frac{\mu_0}{4\pi} \int_{V} \vec{\nabla}_{\vec{r}}~ \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{r}~' + \frac{1}{c^2}  \frac{1}{4\pi \epsilon_0} \int_{V} \frac{\del}{\del t}\frac{\rho(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{r}~'\nn\\
&=  \frac{\mu_0}{4\pi} \int_{V} \vec{\nabla}_{\vec{r}}~ \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \frac{\del}{\del t}\frac{\rho(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{r}~',\nn\\
\eal
\eeq
where we used $c^2 = \frac{1}{\mu_0\epsilon_0}$. Now consider the first term in the integrand
\beq
\bal
\vec{\nabla}_{\vec{r}}~ \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} &= \vec{j}(\vec{r}~', t_{ret}) \vec{\nabla}_{\vec{r}} \left( \frac{1}{|\vec{r} - \vec{r}~'|}\right) + \frac{1}{|\vec{r} - \vec{r}~'|} \del_{t_{ret}}\vec{j}(\vec{r}~', t_{ret}) \vec{\nabla}_{\vec{r}}~ t_{ret}\nn \\
&= -\vec{j}(\vec{r}~', t_{ret}) \frac{\vec{r} - \vec{r}~'}{|\vec{r} - \vec{r}~'|^3} - \frac{1}{c} \frac{\vec{r} - \vec{r}~'}{|\vec{r} - \vec{r}~'|^2} \del_{t_{ret}}\vec{j}(\vec{r}~', t_{ret})
\eal
\eeq
On the other hand we also have
\beq
\bal
\vec{\nabla}_{\vec{r}~'}~ \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} &= \vec{j}(\vec{r}~', t_{ret}) \vec{\nabla}_{\vec{r}~'} \left( \frac{1}{|\vec{r} - \vec{r}~'|}\right) + \frac{1}{|\vec{r} - \vec{r}~'|} \left( \vec{\nabla}_{\vec{r}~'} \vec{j}(\vec{r}~', t_{ret})\Bigr |_{t_{ret}} + \del_{t_{ret}}\vec{j}(\vec{r}~', t_{ret}) \vec{\nabla}_{\vec{r}~'}~ t_{ret}\right)\nn \\
&= \vec{j}(\vec{r}~', t_{ret}) \frac{\vec{r} - \vec{r}~'}{|\vec{r} - \vec{r}~'|^3} + \frac{1}{|\vec{r} - \vec{r}~'|} \left( \vec{\nabla}_{\vec{r}~'} \vec{j}(\vec{r}~', t_{ret}) \Bigr |_{t_{ret}}+ \frac{1}{c}  \frac{\vec{r} - \vec{r}~'}{|\vec{r} - \vec{r}~'|} \del_{t_{ret}}\vec{j}(\vec{r}~', t_{ret}) \right),
\eal
\eeq
which means that we can write
\beq
\vec{\nabla}_{\vec{r}}~ \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} + \vec{\nabla}_{\vec{r}~'}~ \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} =  \frac{\vec{\nabla}_{\vec{r}~'} \vec{j}(\vec{r}~', t_{ret})\Bigr |_{t_{ret}}}{|\vec{r} - \vec{r}~'|}. \nn
\eeq
Plugging in this into \eqref{eqn: step1} yields
\beq
\vec{\nabla} \vec{A} + \frac{1}{c^2}\frac{\del \varphi}{\del t} = \frac{\mu_0}{4\pi} \int_{V} - \vec{\nabla}_{\vec{r}~'}~ \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} + \underbrace{ \frac{\vec{\nabla}_{\vec{r}~'} \vec{j}(\vec{r}~', t_{ret})\Bigr |_{t_{ret}}}{|\vec{r} - \vec{r}~'|} + \frac{\del}{\del t}\frac{\rho(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|}}_{= 0 \text{ due to continuity equation}} ~\dm \vec{r}~'. \nn 
\eeq
For the remaining first term we use \textit{Stokes Law}
\beq
\vec{\nabla} \vec{A} + \frac{1}{c^2}\frac{\del \varphi}{\del t} = -\frac{\mu_0}{4\pi} \int_{V} \vec{\nabla}_{\vec{r}~'}~ \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{r}~' =  - \frac{\mu_0}{4\pi} \oint_{\del V}  \frac{\vec{j}(\vec{r}~', t_{ret})}{|\vec{r} - \vec{r}~'|} \dm \vec{\sigma} = 0, \nn
\eeq
because the current density vanishes at infinity. That's what we wanted to show.

%======================== Softwarestack and Documentation ============================
\chapter{Softwarestack and Documentation}
The following Softwarestack was used to create this thesis:
\begin{itemize}
\item IDE: XCode Version 8.3.3 (8E3004b)
\item Version Control System: Git
\item Version Control IDE: Atlassian SourceTree Version 2.5.2(111)
\item Repository: \href{https://github.com/dsymhoven/masterarbeit}{https://github.com/dsymhoven/masterarbeit}
\item Package Manager: MacPorts Version 2.3.5
\item Plots: Python2.7
\item Texteditor: Atom Version 1.17.2
\item Documentation: Doxygen Version 1.8.13
\item Documentation: \href{https://dsymhoven.github.io/masterarbeit/}{https://dsymhoven.github.io/masterarbeit/}
\end{itemize}

%======================== Normalization ============================
\chapter{Normalization}
\label{app: Normalization}
In this chapter we show how we can make the basic equations from Section \ref{sec: Equations of Motion} dimensionless. Even though it's not necessary, it's always advisable in numerics to have a dimensionless systems for reasons of simplicity and clarity. In addition to the transformation equations we will also present the dimensionless Lorentz-Newton equation \eqref{eqn: Lorentz-Newton}, the damping term, i.e. Landau-Lifschitz equation \eqref{eqn: Landau-Lifschitz} and of course the Liénard-Wiechart equations \eqref{eqn: Liénard-Wiechert}.\\
\newline
To make the physical entities dimensionless we introduce a characteristic frequency $\omega$. Dimensionless parameters are denoted with a tilde. \\
With the following transformations
\beq
\bal
t &= \frac{1}{\omega}\tilde{t}, \\
\vec{r} &= \frac{c}{\omega}\tilde{\vec{r}}, \\
R &= \frac{c}{\omega}\tilde{R}, \\
\dm \tau &= \frac{1}{\omega}\dm\tilde{s}, \\
F^{\mu\nu} &= \frac{\omega m_e}{q}\tilde{F}^{\mu\nu}, \\
F^{\mu\nu}_{\quad\text{ext}} &= \frac{\omega m_e}{e}\tilde{F}^{\mu\nu}_{\quad\text{ext}}, \\
F^{\mu\nu}_{\quad\text{lw}} &= \frac{q}{4\pi\epsilon_0}\frac{\omega^2}{c^3}\tilde{F}^{\mu\nu}_{\quad\text{lw}}, \\
F^{\mu\nu}&= F^{\mu\nu}_{\quad\text{ext}} + \frac{q^2}{4\pi\epsilon_0}\frac{\omega^2}{c^3}\tilde{F}^{\mu\nu}_{\quad\text{lw}}
\eal
\eeq
the aforementioned equations become dimensionless, where $F^{\mu\nu}_{\quad\text{ext}}$ denotes the external fields, $F^{\mu\nu}_{\quad\text{lw}}$ the Liénard-Wiechert fields and $F^{\mu\nu}$ the total fields. If we define the characteristic frequency $\omega$ such, that 
\beq
\bal
\frac{q^2}{4\pi\epsilon_0}\frac{\omega^2}{c^3} &\stackrel{!}{=} 1 \\
\Longrightarrow \omega &= 4\pi\epsilon_0 \frac{m_ec^3}{q^2},
\eal
\eeq
both the external and the Liénard-Wiechert fields have the same units
\beq
\frac{\omega m_e}{q} = 4\pi\epsilon_0 \frac{m^2_ec^3}{q^3}.
\eeq
In the following we present the basic equations from Section \ref{sec: Equations of Motion} in dimensionless form: \\
The dimensionless Lorentz-Newton equation \eqref{eqn: Lorentz-Newton} reads
\beq
\frac{\dm u^{\mu}}{\dm\tilde{s}} = \biggl( \tilde{F}^{\mu\nu}_{\quad\text{lw}}(x^{\mu}) + \tilde{F}^{\mu\nu}_{\quad\text{ext}}(x^{\mu})\biggr) u^{\nu} + \tilde{g}^{\mu}.
\eeq
The Landau-Lifschitz equation \eqref{eqn: Landau-Lifschitz} becomes
\beq
\tilde{g}^{\mu} = \frac{2}{3}\biggl(\frac{\del \tilde{F}^{\mu\nu}}{\del \tilde{x}^{\xi}}u^{\nu}u^{\xi} - \tilde{F}^{\mu\xi}\tilde{F}_{\nu\xi}u^{\nu} + (\tilde{F}_{\nu\xi}u^{\xi})(\tilde{F}^{\nu\pi}u_{\pi})u^{\mu}\biggr),
\eeq
and finally the Liénard-Wiechart equations \eqref{eqn: Liénard-Wiechert}
\beq
\bal
\vec{\tilde{E}}(\vec{\tilde{r}}, \tilde{t}) &= \left( \frac{\vec{n}(\vec{\tilde{r}},\tilde{t}') - \vec{\beta}(\tilde{t})}{ \gamma^2(1 - \vec{\beta}(\tilde{t}) \cdot \vec{n}(\vec{\tilde{r}},\tilde{t}'))^3 \tilde{R}^2(\vec{\tilde{r}},\tilde{t}')} \right. \\
& \left. + \frac{\vec{n}(\vec{\tilde{r}},\tilde{t}') \times (\vec{n}(\vec{\tilde{r}},\tilde{t}') - \vec{\beta}(\tilde{t})) \times \dot{\vec{\beta}}(\tilde{t})}{(1 - \vec{\beta}(\tilde{t}) \cdot \vec{n}(\vec{\tilde{r}},\tilde{t}'))^3 \tilde{R}(\vec{\tilde{r}},\tilde{t}')}\right)\Biggr |_{\tilde{t}' = \tilde{t}_{ret}}, \\
\vec{B}(\vec{\tilde{r}}, \tilde{t}) &= \left(\vec{n}(\vec{\tilde{r}},\tilde{t}') \times \vec{E}(\vec{\tilde{r}}, \tilde{t})\right)\Biggr |_{\tilde{t}' = \tilde{t}_{ret}}.
\eal
\eeq
%============================= Abbildungsverzeichnis ===========================
\listoffigures

%======================== Literaturverzeichnis ========================

\bibliography{reference}{}
\bibliographystyle{plain}

%================================= ERKLÄRUNG=============================
\include{declaration}


\end{document}











